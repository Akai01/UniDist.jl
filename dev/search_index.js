var documenterSearchIndex = {"docs":
[{"location":"api/survival/#survival-analysis","page":"Survival Analysis","title":"Survival Analysis","text":"UniDist.jl provides built-in functions for survival analysis, commonly used in reliability engineering, medical research, and actuarial science.","category":"section"},{"location":"api/survival/#Overview","page":"Survival Analysis","title":"Overview","text":"Survival analysis deals with time-to-event data. The key functions are:\n\nFunction Formula Description\nsf(d, x) S(x) = 1 - F(x) Survival function\nhazard(d, x) h(x) = f(x) / S(x) Hazard function\ncumhaz(d, x) H(x) = -log(S(x)) Cumulative hazard\n\nwhere F(x) is the CDF and f(x) is the PDF.\n\n","category":"section"},{"location":"api/survival/#Survival-Function","page":"Survival Analysis","title":"Survival Function","text":"","category":"section"},{"location":"api/survival/#sf-Survival-Function","page":"Survival Analysis","title":"sf - Survival Function","text":"The survival function S(x) = P(X > x) gives the probability of surviving beyond time x.\n\nsf(dist, x)\n\nFormula: sf(d, x) = 1 - cdf(d, x)\n\nExamples:\n\n# Exponential lifetime with mean 10\nd = Exponential(10.0)\n\nsf(d, 5)              # ≈ 0.607 (probability of surviving past t=5)\nsf(d, 10)             # ≈ 0.368 (probability of surviving past t=10)\nsf(d, 20)             # ≈ 0.135\n\n# Verify: sf + cdf = 1\nsf(d, 5) + cdf(d, 5)  # 1.0\n\nInterpretation:\n\nsf(d, 0) = 1 (everyone alive at start)\nsf(d, ∞) = 0 (eventually everyone fails)\nMonotonically decreasing\n\n","category":"section"},{"location":"api/survival/#Hazard-Function","page":"Survival Analysis","title":"Hazard Function","text":"","category":"section"},{"location":"api/survival/#hazard-Instantaneous-Failure-Rate","page":"Survival Analysis","title":"hazard - Instantaneous Failure Rate","text":"The hazard function h(x) represents the instantaneous failure rate at time x, given survival up to time x.\n\nhazard(dist, x)\n\nFormula: hazard(d, x) = pdf(d, x) / sf(d, x)\n\nExamples:\n\n# Exponential: constant hazard (memoryless property)\nd = Exponential(10.0)\nhazard(d, 1)          # 0.1\nhazard(d, 5)          # 0.1\nhazard(d, 100)        # 0.1 (same at all times!)\n\n# Weibull: flexible hazard shapes\n# Shape < 1: decreasing hazard (infant mortality)\nd1 = Weibull(0.5, 10)\nhazard(d1, 1)         # High\nhazard(d1, 10)        # Lower\n\n# Shape = 1: constant hazard (same as Exponential)\nd2 = Weibull(1.0, 10)\nhazard(d2, 1)         # Constant\nhazard(d2, 10)        # Same\n\n# Shape > 1: increasing hazard (wear-out)\nd3 = Weibull(2.0, 10)\nhazard(d3, 1)         # Low\nhazard(d3, 10)        # Higher\n\nInterpretation:\n\nUnits: failures per unit time\nCan increase, decrease, or remain constant\nKey for reliability modeling\n\n","category":"section"},{"location":"api/survival/#Cumulative-Hazard-Function","page":"Survival Analysis","title":"Cumulative Hazard Function","text":"","category":"section"},{"location":"api/survival/#cumhaz-Cumulative-Hazard","page":"Survival Analysis","title":"cumhaz - Cumulative Hazard","text":"The cumulative hazard H(x) is the integral of the hazard function from 0 to x.\n\ncumhaz(dist, x)\n\nFormula: cumhaz(d, x) = -log(sf(d, x))\n\nExamples:\n\nd = Exponential(10.0)\n\ncumhaz(d, 5)          # 0.5\ncumhaz(d, 10)         # 1.0\ncumhaz(d, 20)         # 2.0\n\n# Relationship with survival function\nexp(-cumhaz(d, 5))    # ≈ sf(d, 5)\n\nProperties:\n\ncumhaz(d, 0) = 0\nMonotonically increasing\ncumhaz(d, x) → ∞ as x → ∞\n\n","category":"section"},{"location":"api/survival/#Practical-Applications","page":"Survival Analysis","title":"Practical Applications","text":"","category":"section"},{"location":"api/survival/#Reliability-Analysis","page":"Survival Analysis","title":"Reliability Analysis","text":"# Component lifetime follows Weibull distribution\n# Shape = 2 indicates wear-out failure mode\ncomponent = Weibull(2.0, 1000)  # Scale = 1000 hours\n\n# Probability of surviving 500 hours\nsf(component, 500)    # ≈ 0.779\n\n# Probability of failing between 500 and 1000 hours\nsf(component, 500) - sf(component, 1000)  # ≈ 0.411\n\n# Hazard rate at 500 hours\nhazard(component, 500)  # Instantaneous failure rate","category":"section"},{"location":"api/survival/#Medical-Survival-Analysis","page":"Survival Analysis","title":"Medical Survival Analysis","text":"# Patient survival follows Exponential(median_survival)\n# If median survival is 24 months\nmedian_survival = 24\nd = Exponential(median_survival / log(2))\n\n# 1-year survival probability\nsf(d, 12)             # Probability of surviving 1 year\n\n# 5-year survival probability\nsf(d, 60)             # Probability of surviving 5 years\n\n# Median survival time\nquantile(d, 0.5)      # Time at which 50% have survived","category":"section"},{"location":"api/survival/#Comparing-Distributions","page":"Survival Analysis","title":"Comparing Distributions","text":"# Compare hazard patterns\nexp_dist = Exponential(10)\nweibull_increasing = Weibull(2.0, 10)\nweibull_decreasing = Weibull(0.5, 10)\n\ntimes = [1, 5, 10, 15, 20]\n\nprintln(\"Time | Exponential | Weibull(2) | Weibull(0.5)\")\nfor t in times\n    h_exp = round(hazard(exp_dist, t), digits=4)\n    h_inc = round(hazard(weibull_increasing, t), digits=4)\n    h_dec = round(hazard(weibull_decreasing, t), digits=4)\n    println(\"$t    | $h_exp      | $h_inc     | $h_dec\")\nend","category":"section"},{"location":"api/survival/#Calculating-Expected-Remaining-Lifetime","page":"Survival Analysis","title":"Calculating Expected Remaining Lifetime","text":"# Mean residual life at time t\n# E[X - t | X > t]\nfunction mean_residual_life(d, t, upper=1000)\n    # Approximate by numerical integration\n    integrand(x) = sf(d, x) / sf(d, t)\n    # Integration from t to upper\n    # (simplified approximation)\n    dx = 0.1\n    xs = t:dx:upper\n    sum(sf(d, x) / sf(d, t) * dx for x in xs)\nend\n\nd = Exponential(10)\nmean_residual_life(d, 0)   # ≈ 10 (memoryless: same as original mean)\nmean_residual_life(d, 5)   # ≈ 10 (memoryless property!)\n\n","category":"section"},{"location":"api/survival/#Vectorized-Operations","page":"Survival Analysis","title":"Vectorized Operations","text":"All survival functions support vectorized operations:\n\nd = Weibull(2.0, 100)\ntimes = [10, 25, 50, 75, 100, 150, 200]\n\n# Survival probabilities at multiple times\nsf(d, times)\n\n# Hazard rates at multiple times\nhazard(d, times)\n\n# Cumulative hazard at multiple times\ncumhaz(d, times)\n\n","category":"section"},{"location":"api/survival/#Common-Survival-Distributions","page":"Survival Analysis","title":"Common Survival Distributions","text":"Distribution Hazard Shape Use Case\nExponential Constant Memoryless failures\nWeibull (β < 1) Decreasing Infant mortality\nWeibull (β = 1) Constant Random failures\nWeibull (β > 1) Increasing Wear-out failures\nLogNormal Non-monotonic Fatigue failures\nGamma Flexible Repair times\nGompertz Increasing Human mortality","category":"section"},{"location":"examples/statistical-analysis/#statistical-analysis","page":"Statistical Analysis","title":"Statistical Analysis","text":"This page demonstrates using UniDist.jl for common statistical analysis tasks.","category":"section"},{"location":"examples/statistical-analysis/#Hypothesis-Testing","page":"Statistical Analysis","title":"Hypothesis Testing","text":"","category":"section"},{"location":"examples/statistical-analysis/#One-Sample-Z-Test","page":"Statistical Analysis","title":"One-Sample Z-Test","text":"using UniDist\n\n# Test if sample mean differs from hypothesized value\n# H₀: μ = 100, H₁: μ ≠ 100\n\nsample_mean = 103.5\nsample_size = 50\nknown_sd = 15\nhypothesized_mean = 100\n\n# Calculate z-statistic\nse = known_sd / sqrt(sample_size)\nz = (sample_mean - hypothesized_mean) / se\n\n# P-value (two-tailed)\nstandard_normal = Normal(0, 1)\np_value = 2 * (1 - cdf(standard_normal, abs(z)))\n\nprintln(\"Z-statistic: $(round(z, digits=3))\")\nprintln(\"P-value: $(round(p_value, digits=4))\")\n\nif p_value < 0.05\n    println(\"Reject H₀ at α = 0.05\")\nelse\n    println(\"Fail to reject H₀ at α = 0.05\")\nend","category":"section"},{"location":"examples/statistical-analysis/#Chi-Square-Goodness-of-Fit","page":"Statistical Analysis","title":"Chi-Square Goodness of Fit","text":"using UniDist\n\n# Test if observed frequencies match expected\nobserved = [45, 35, 20]  # Observed counts\nexpected = [40, 40, 20]  # Expected counts\n\n# Chi-square statistic\nchi_sq = sum((o - e)^2 / e for (o, e) in zip(observed, expected))\n\n# Degrees of freedom = categories - 1\ndf = length(observed) - 1\n\n# P-value\nchi_dist = ChiSquare(df)\np_value = 1 - cdf(chi_dist, chi_sq)\n\nprintln(\"χ² statistic: $(round(chi_sq, digits=3))\")\nprintln(\"Degrees of freedom: $df\")\nprintln(\"P-value: $(round(p_value, digits=4))\")","category":"section"},{"location":"examples/statistical-analysis/#F-Test-for-Variance-Ratio","page":"Statistical Analysis","title":"F-Test for Variance Ratio","text":"using UniDist\n\n# Test if two populations have equal variances\nvar1, n1 = 25.0, 30  # Sample 1: variance, size\nvar2, n2 = 16.0, 25  # Sample 2: variance, size\n\n# F-statistic (larger variance in numerator)\nf_stat = var1 / var2\n\n# Degrees of freedom\ndf1 = n1 - 1\ndf2 = n2 - 1\n\n# P-value (two-tailed)\nf_dist = F(df1, df2)\np_value = 2 * min(cdf(f_dist, f_stat), 1 - cdf(f_dist, f_stat))\n\nprintln(\"F-statistic: $(round(f_stat, digits=3))\")\nprintln(\"P-value: $(round(p_value, digits=4))\")\n\n","category":"section"},{"location":"examples/statistical-analysis/#Confidence-Intervals","page":"Statistical Analysis","title":"Confidence Intervals","text":"","category":"section"},{"location":"examples/statistical-analysis/#CI-for-Population-Mean-(Known-Variance)","page":"Statistical Analysis","title":"CI for Population Mean (Known Variance)","text":"using UniDist\n\nsample_mean = 75.3\nknown_sd = 10.0\nn = 40\nconfidence = 0.95\n\n# Z critical value\nz_crit = quantile(Normal(0, 1), 1 - (1 - confidence) / 2)\n\n# Margin of error\nse = known_sd / sqrt(n)\nmargin = z_crit * se\n\n# Confidence interval\nci_lower = sample_mean - margin\nci_upper = sample_mean + margin\n\nprintln(\"$(Int(confidence*100))% CI: [$(round(ci_lower, digits=2)), $(round(ci_upper, digits=2))]\")","category":"section"},{"location":"examples/statistical-analysis/#CI-for-Population-Proportion","page":"Statistical Analysis","title":"CI for Population Proportion","text":"using UniDist\n\n# Survey: 120 out of 400 prefer option A\nsuccesses = 120\nn = 400\nconfidence = 0.95\n\n# Sample proportion\np_hat = successes / n\n\n# Standard error\nse = sqrt(p_hat * (1 - p_hat) / n)\n\n# Z critical value\nz_crit = quantile(Normal(0, 1), 1 - (1 - confidence) / 2)\n\n# Confidence interval\nci_lower = p_hat - z_crit * se\nci_upper = p_hat + z_crit * se\n\nprintln(\"Sample proportion: $(round(p_hat, digits=3))\")\nprintln(\"$(Int(confidence*100))% CI: [$(round(ci_lower, digits=3)), $(round(ci_upper, digits=3))]\")\n\n","category":"section"},{"location":"examples/statistical-analysis/#Power-Analysis","page":"Statistical Analysis","title":"Power Analysis","text":"","category":"section"},{"location":"examples/statistical-analysis/#Sample-Size-for-Desired-Power","page":"Statistical Analysis","title":"Sample Size for Desired Power","text":"using UniDist\n\n# Detect effect size d = 0.5 with 80% power at α = 0.05\n\neffect_size = 0.5\nalpha = 0.05\npower = 0.80\n\n# Critical values\nz_alpha = quantile(Normal(0, 1), 1 - alpha/2)  # Two-tailed\nz_beta = quantile(Normal(0, 1), power)\n\n# Required sample size per group (two-sample t-test approximation)\nn = 2 * ((z_alpha + z_beta) / effect_size)^2\n\nprintln(\"Required sample size per group: $(ceil(Int, n))\")","category":"section"},{"location":"examples/statistical-analysis/#Power-for-Given-Sample-Size","page":"Statistical Analysis","title":"Power for Given Sample Size","text":"using UniDist\n\n# Calculate power for n=50 per group, effect size=0.4, α=0.05\n\nn = 50\neffect_size = 0.4\nalpha = 0.05\n\n# Non-centrality parameter\nncp = effect_size * sqrt(n / 2)\n\n# Critical value under null\nz_crit = quantile(Normal(0, 1), 1 - alpha/2)\n\n# Power = P(reject H₀ | H₁ true)\n# Under alternative, test statistic ~ N(ncp, 1)\nalt_dist = Normal(ncp, 1)\npower = 1 - cdf(alt_dist, z_crit) + cdf(alt_dist, -z_crit)\n\nprintln(\"Power: $(round(power * 100, digits=1))%\")\n\n","category":"section"},{"location":"examples/statistical-analysis/#Distribution-Fitting-Assessment","page":"Statistical Analysis","title":"Distribution Fitting Assessment","text":"","category":"section"},{"location":"examples/statistical-analysis/#Q-Q-Plot-Data","page":"Statistical Analysis","title":"Q-Q Plot Data","text":"using UniDist\n\n# Generate theoretical quantiles for Q-Q plot\ndata = [2.3, 3.1, 3.5, 4.2, 4.8, 5.1, 5.9, 6.3, 7.1, 8.2]\nn = length(data)\n\n# Sort data\nsorted_data = sort(data)\n\n# Theoretical quantiles (standard normal)\ntheoretical_dist = Normal(0, 1)\nprobabilities = [(i - 0.5) / n for i in 1:n]\ntheoretical_quantiles = quantile(theoretical_dist, probabilities)\n\nprintln(\"Data Quantile\\tTheoretical Quantile\")\nfor (d, t) in zip(sorted_data, theoretical_quantiles)\n    println(\"$(round(d, digits=2))\\t\\t$(round(t, digits=2))\")\nend","category":"section"},{"location":"examples/statistical-analysis/#Probability-Plot-Correlation","page":"Statistical Analysis","title":"Probability Plot Correlation","text":"using UniDist\n\n# Check if data follows exponential distribution\ndata = [0.5, 0.8, 1.2, 1.5, 2.1, 2.8, 3.5, 4.2, 5.1, 7.3]\nn = length(data)\n\n# Fit exponential: estimate rate from data\nmean_data = sum(data) / n\nfitted_dist = Exponential(mean_data)\n\n# Theoretical quantiles\nsorted_data = sort(data)\nprobs = [(i - 0.5) / n for i in 1:n]\ntheoretical = quantile(fitted_dist, probs)\n\n# Correlation coefficient\nmean_sorted = sum(sorted_data) / n\nmean_theoretical = sum(theoretical) / n\n\nnumerator = sum((sorted_data[i] - mean_sorted) * (theoretical[i] - mean_theoretical) for i in 1:n)\ndenom_sorted = sqrt(sum((x - mean_sorted)^2 for x in sorted_data))\ndenom_theoretical = sqrt(sum((x - mean_theoretical)^2 for x in theoretical))\n\ncorrelation = numerator / (denom_sorted * denom_theoretical)\n\nprintln(\"Probability plot correlation: $(round(correlation, digits=4))\")\nprintln(\"(Values close to 1 suggest good fit)\")\n\n","category":"section"},{"location":"examples/statistical-analysis/#Risk-Analysis","page":"Statistical Analysis","title":"Risk Analysis","text":"","category":"section"},{"location":"examples/statistical-analysis/#Value-at-Risk-(VaR)","page":"Statistical Analysis","title":"Value at Risk (VaR)","text":"using UniDist\n\n# Portfolio returns assumed to follow Normal distribution\n# Mean daily return: 0.05%, Volatility: 2%\ndaily_return = Normal(0.0005, 0.02)\n\n# VaR at different confidence levels\nprintln(\"Value at Risk (daily):\")\nfor conf in [0.90, 0.95, 0.99]\n    var = -quantile(daily_return, 1 - conf)\n    println(\"$(Int(conf*100))% VaR: $(round(var * 100, digits=2))%\")\nend","category":"section"},{"location":"examples/statistical-analysis/#Expected-Shortfall-(CVaR)","page":"Statistical Analysis","title":"Expected Shortfall (CVaR)","text":"using UniDist\n\n# For Normal distribution, ES has closed form\nμ = 0.0005\nσ = 0.02\nreturns = Normal(μ, σ)\n\nalpha = 0.05  # 95% confidence\n\n# VaR\nvar = -quantile(returns, alpha)\n\n# Expected Shortfall for Normal: ES = μ + σ * φ(Φ⁻¹(α)) / α\n# where φ is PDF and Φ⁻¹ is quantile of standard normal\nz_alpha = quantile(Normal(0, 1), alpha)\nes = -(μ - σ * pdf(Normal(0, 1), z_alpha) / alpha)\n\nprintln(\"95% VaR: $(round(var * 100, digits=2))%\")\nprintln(\"95% ES (CVaR): $(round(es * 100, digits=2))%\")\n\n","category":"section"},{"location":"examples/statistical-analysis/#Quality-Control","page":"Statistical Analysis","title":"Quality Control","text":"","category":"section"},{"location":"examples/statistical-analysis/#Process-Capability","page":"Statistical Analysis","title":"Process Capability","text":"using UniDist\n\n# Process specifications\nlsl = 95   # Lower specification limit\nusl = 105  # Upper specification limit\n\n# Process parameters (from sample)\nprocess_mean = 100.2\nprocess_sd = 1.5\n\nprocess = Normal(process_mean, process_sd)\n\n# Defect rates\np_below_lsl = cdf(process, lsl)\np_above_usl = 1 - cdf(process, usl)\ntotal_defect_rate = p_below_lsl + p_above_usl\n\nprintln(\"P(below LSL): $(round(p_below_lsl * 1e6, digits=1)) ppm\")\nprintln(\"P(above USL): $(round(p_above_usl * 1e6, digits=1)) ppm\")\nprintln(\"Total defect rate: $(round(total_defect_rate * 1e6, digits=1)) ppm\")\n\n# Process capability indices\ncp = (usl - lsl) / (6 * process_sd)\ncpk = min(usl - process_mean, process_mean - lsl) / (3 * process_sd)\n\nprintln(\"\\nCp: $(round(cp, digits=3))\")\nprintln(\"Cpk: $(round(cpk, digits=3))\")","category":"section"},{"location":"examples/statistical-analysis/#Control-Chart-Limits","page":"Statistical Analysis","title":"Control Chart Limits","text":"using UniDist\n\n# X-bar chart for sample means\n# Process: μ = 50, σ = 5, sample size n = 4\n\nmu = 50\nsigma = 5\nn = 4\n\n# Distribution of sample means\nse = sigma / sqrt(n)\nxbar_dist = Normal(mu, se)\n\n# 3-sigma control limits\nlcl = quantile(xbar_dist, 0.00135)  # ≈ μ - 3σ/√n\nucl = quantile(xbar_dist, 0.99865)  # ≈ μ + 3σ/√n\n\nprintln(\"Center Line: $mu\")\nprintln(\"LCL: $(round(lcl, digits=2))\")\nprintln(\"UCL: $(round(ucl, digits=2))\")\n\n# Probability of false alarm (Type I error)\np_false_alarm = 2 * cdf(xbar_dist, lcl)\nprintln(\"P(false alarm): $(round(p_false_alarm * 100, digits=3))%\")\n\n","category":"section"},{"location":"examples/statistical-analysis/#Acceptance-Sampling","page":"Statistical Analysis","title":"Acceptance Sampling","text":"","category":"section"},{"location":"examples/statistical-analysis/#Single-Sampling-Plan","page":"Statistical Analysis","title":"Single Sampling Plan","text":"using UniDist\n\n# Lot size N = 1000, sample size n = 50, accept if defects ≤ c = 2\n# What is the probability of accepting a lot with 5% defective?\n\nn = 50\nc = 2\np_defective = 0.05\n\n# Number of defectives in sample follows Binomial(n, p)\ndefectives = Binomial(n, p_defective)\n\n# Probability of acceptance\np_accept = cdf(defectives, c)\n\nprintln(\"Sampling plan: n=$n, c=$c\")\nprintln(\"If lot is 5% defective:\")\nprintln(\"P(accept) = $(round(p_accept * 100, digits=1))%\")\nprintln(\"P(reject) = $(round((1 - p_accept) * 100, digits=1))%\")","category":"section"},{"location":"examples/statistical-analysis/#Operating-Characteristic-Curve","page":"Statistical Analysis","title":"Operating Characteristic Curve","text":"using UniDist\n\n# OC curve for sampling plan n=50, c=2\nn = 50\nc = 2\n\nprintln(\"Lot defect rate\\tP(accept)\")\nfor p in [0.01, 0.02, 0.03, 0.05, 0.07, 0.10, 0.15]\n    defectives = Binomial(n, p)\n    p_accept = cdf(defectives, c)\n    println(\"$(Int(p*100))%\\t\\t$(round(p_accept * 100, digits=1))%\")\nend","category":"section"},{"location":"api/intervals/#statistical-intervals","page":"Statistical Intervals","title":"Statistical Intervals","text":"UniDist.jl provides functions for computing statistical intervals from distributions, useful for uncertainty quantification, Bayesian inference, and hypothesis testing.","category":"section"},{"location":"api/intervals/#Overview","page":"Statistical Intervals","title":"Overview","text":"Function Description Best For\ninterval(d, α) Equal-tailed interval Symmetric distributions\nhdi(d, mass) Highest Density Interval Skewed/multimodal distributions\n\n","category":"section"},{"location":"api/intervals/#Equal-Tailed-Interval","page":"Statistical Intervals","title":"Equal-Tailed Interval","text":"","category":"section"},{"location":"api/intervals/#interval-Symmetric-Probability-Interval","page":"Statistical Intervals","title":"interval - Symmetric Probability Interval","text":"Computes an equal-tailed interval that contains (1 - α) × 100% of the probability mass.\n\ninterval(dist, alpha=0.05)\n\nArguments:\n\ndist: A distribution object\nalpha: Significance level (default: 0.05 for 95% interval)\n\nReturns: Tuple (lower, upper) where:\n\nlower = quantile(dist, α/2)\nupper = quantile(dist, 1 - α/2)\n\nExamples:\n\n# 95% interval for standard normal\nd = Normal(0, 1)\ninterval(d, 0.05)     # (-1.96, 1.96)\n\n# 90% interval\ninterval(d, 0.10)     # (-1.645, 1.645)\n\n# 99% interval\ninterval(d, 0.01)     # (-2.576, 2.576)\n\nProperties:\n\nEqual probability in each tail: P(X < lower) = P(X > upper) = α/2\nAlways symmetric in probability, not necessarily in value\nSimple and widely understood\n\n","category":"section"},{"location":"api/intervals/#Highest-Density-Interval","page":"Statistical Intervals","title":"Highest Density Interval","text":"","category":"section"},{"location":"api/intervals/#hdi-Highest-Density-Interval-(HDI/HPD)","page":"Statistical Intervals","title":"hdi - Highest Density Interval (HDI/HPD)","text":"Computes the Highest Density Interval - the narrowest interval containing the specified probability mass.\n\nhdi(dist, mass=0.9; grid=2048, eps=1e-6)  # Continuous\nhdi(dist, mass=0.9)                        # Discrete\n\nArguments:\n\ndist: A distribution object\nmass: Probability mass to contain (default: 0.9 for 90% HDI)\ngrid: Grid resolution for continuous distributions (default: 2048)\neps: Epsilon for tail trimming (default: 1e-6)\n\nReturns: Tuple (lower, upper)\n\nExamples:\n\n# HDI for symmetric distribution (same as equal-tailed)\nd = Normal(0, 1)\nhdi(d, 0.95)          # ≈ (-1.96, 1.96)\n\n# HDI for skewed distribution (narrower than equal-tailed)\nd = Exponential(1.0)\nhdi(d, 0.95)          # Narrower interval\ninterval(d, 0.05)     # Wider interval (equal-tailed)\n\n# HDI for discrete distribution\nd = Binomial(10, 0.3)\nhdi(d, 0.9)           # Smallest set of values containing 90%\n\n","category":"section"},{"location":"api/intervals/#Comparing-Interval-Types","page":"Statistical Intervals","title":"Comparing Interval Types","text":"","category":"section"},{"location":"api/intervals/#Symmetric-Distributions","page":"Statistical Intervals","title":"Symmetric Distributions","text":"For symmetric distributions (Normal, Cauchy, Logistic, etc.), both methods give the same result:\n\nd = Normal(0, 1)\n\ninterval(d, 0.05)     # (-1.96, 1.96)\nhdi(d, 0.95)          # (-1.96, 1.96) - same!","category":"section"},{"location":"api/intervals/#Skewed-Distributions","page":"Statistical Intervals","title":"Skewed Distributions","text":"For skewed distributions, HDI is narrower:\n\nd = Exponential(1.0)\n\n# Equal-tailed: wider\nlo_eq, hi_eq = interval(d, 0.05)\nwidth_eq = hi_eq - lo_eq\n\n# HDI: narrower\nlo_hdi, hi_hdi = hdi(d, 0.95)\nwidth_hdi = hi_hdi - lo_hdi\n\nprintln(\"Equal-tailed width: $width_eq\")\nprintln(\"HDI width: $width_hdi\")\n# HDI is always ≤ equal-tailed width","category":"section"},{"location":"api/intervals/#Visual-Comparison","page":"Statistical Intervals","title":"Visual Comparison","text":"using UniDist\n\n# Gamma distribution (skewed)\nd = Gamma(2, 2)\n\n# Equal-tailed 90% interval\neq_lo, eq_hi = interval(d, 0.10)\nprintln(\"Equal-tailed: [$eq_lo, $eq_hi], width = $(eq_hi - eq_lo)\")\n\n# HDI 90% interval\nhdi_lo, hdi_hi = hdi(d, 0.90)\nprintln(\"HDI: [$hdi_lo, $hdi_hi], width = $(hdi_hi - hdi_lo)\")\n\n# The HDI is narrower and shifted toward the mode\n\n","category":"section"},{"location":"api/intervals/#When-to-Use-Each-Method","page":"Statistical Intervals","title":"When to Use Each Method","text":"","category":"section"},{"location":"api/intervals/#Use-Equal-Tailed-Intervals-When:","page":"Statistical Intervals","title":"Use Equal-Tailed Intervals When:","text":"Distribution is symmetric\nYou want equal error probability in both tails\nCommunicating with audiences familiar with confidence intervals\nComputing p-values (two-tailed tests)","category":"section"},{"location":"api/intervals/#Use-HDI-When:","page":"Statistical Intervals","title":"Use HDI When:","text":"Distribution is skewed\nYou want the shortest possible interval\nDoing Bayesian inference\nThe mode is more relevant than the median\nDistribution may be multimodal\n\n","category":"section"},{"location":"api/intervals/#Practical-Applications","page":"Statistical Intervals","title":"Practical Applications","text":"","category":"section"},{"location":"api/intervals/#Confidence-Intervals-for-Parameters","page":"Statistical Intervals","title":"Confidence Intervals for Parameters","text":"# Estimating population mean\n# After Bayesian analysis, posterior is Normal(5.2, 0.8)\nposterior = Normal(5.2, 0.8)\n\n# 95% credible interval\nlo, hi = interval(posterior, 0.05)\nprintln(\"95% CI for mean: [$lo, $hi]\")","category":"section"},{"location":"api/intervals/#Bayesian-Inference","page":"Statistical Intervals","title":"Bayesian Inference","text":"# Beta posterior for success probability\n# Prior: Beta(1, 1), Data: 7 successes, 3 failures\nposterior = Beta(1 + 7, 1 + 3)  # Beta(8, 4)\n\n# 95% HDI\nlo, hi = hdi(posterior, 0.95)\nprintln(\"95% HDI for p: [$lo, $hi]\")\n\n# Compare with equal-tailed\nlo_eq, hi_eq = interval(posterior, 0.05)\nprintln(\"95% Equal-tailed: [$lo_eq, $hi_eq]\")","category":"section"},{"location":"api/intervals/#Predictive-Intervals","page":"Statistical Intervals","title":"Predictive Intervals","text":"# Predict next observation from Poisson(λ=5)\nd = Poisson(5.0)\n\n# 90% prediction interval\nlo, hi = hdi(d, 0.90)\nprintln(\"90% of observations will be in [$lo, $hi]\")","category":"section"},{"location":"api/intervals/#Comparing-Groups","page":"Statistical Intervals","title":"Comparing Groups","text":"# Effect size has posterior Normal(0.5, 0.2)\neffect = Normal(0.5, 0.2)\n\n# 95% HDI\nlo, hi = hdi(effect, 0.95)\n\n# Check if interval excludes zero (evidence of effect)\nif lo > 0 || hi < 0\n    println(\"95% HDI excludes zero: evidence of effect\")\nelse\n    println(\"95% HDI includes zero: no clear evidence\")\nend\n\n","category":"section"},{"location":"api/intervals/#Discrete-Distribution-HDI","page":"Statistical Intervals","title":"Discrete Distribution HDI","text":"For discrete distributions, HDI finds the smallest set of values containing the desired mass:\n\nd = Binomial(20, 0.3)\n\n# Find 90% HDI\nlo, hi = hdi(d, 0.90)\nprintln(\"90% HDI: {$lo, ..., $hi}\")\n\n# Verify the coverage\ncoverage = sum(pdf(d, k) for k in lo:hi)\nprintln(\"Actual coverage: $(round(coverage * 100, digits=1))%\")\n\nNote: For discrete distributions, the actual coverage may exceed the requested mass because probability is concentrated at discrete points.\n\n","category":"section"},{"location":"api/intervals/#Algorithm-Details","page":"Statistical Intervals","title":"Algorithm Details","text":"","category":"section"},{"location":"api/intervals/#Continuous-HDI-Algorithm","page":"Statistical Intervals","title":"Continuous HDI Algorithm","text":"Create a fine grid over the distribution support\nCompute PDF at each grid point\nSort points by density (highest first)\nInclude points until cumulative mass ≥ target\nReturn (min, max) of included points","category":"section"},{"location":"api/intervals/#Discrete-HDI-Algorithm","page":"Statistical Intervals","title":"Discrete HDI Algorithm","text":"Enumerate support of distribution\nCompute PMF at each point\nSort by probability (highest first)\nInclude points until cumulative mass ≥ target\nReturn (min, max) of included points\n\n","category":"section"},{"location":"api/intervals/#Limitations","page":"Statistical Intervals","title":"Limitations","text":"Multimodal distributions: HDI returns a single interval (min to max of high-density points), which may include low-density regions between modes\nDiscrete distributions: Require finite, enumerable support\nNumerical precision: Continuous HDI depends on grid resolution\n\n","category":"section"},{"location":"api/intervals/#API-Reference","page":"Statistical Intervals","title":"API Reference","text":"","category":"section"},{"location":"api/intervals/#UniDist.interval","page":"Statistical Intervals","title":"UniDist.interval","text":"interval(dist, alpha=0.05)\n\nEqual-tailed interval [q(alpha/2), q(1-alpha/2)].\n\n\n\n\n\n","category":"function"},{"location":"api/intervals/#UniDist.hdi","page":"Statistical Intervals","title":"UniDist.hdi","text":"hdi(dist, mass=0.9; grid=2048, eps=1e-6)\n\nA practical HDI/HPD approximation.\n\nContinuous: grid-based density scan on [q(eps), q(1-eps)].\nDiscrete: exact-ish via sorting pmf over finite support.\n\nCurrently expects scalar distribution parameters.\n\n\n\n\n\n","category":"function"},{"location":"api/core/#core-functions","page":"Core Functions","title":"Core Functions","text":"This page documents the core API functions for working with distributions in UniDist.jl.","category":"section"},{"location":"api/core/#Probability-Functions","page":"Core Functions","title":"Probability Functions","text":"","category":"section"},{"location":"api/core/#pdf-Probability-Density/Mass-Function","page":"Core Functions","title":"pdf - Probability Density/Mass Function","text":"Computes the probability density (continuous) or probability mass (discrete) at a given point.\n\npdf(dist, x)\n\nArguments:\n\ndist: A distribution object\nx: Point(s) at which to evaluate\n\nReturns: Probability density or mass value(s)\n\nExamples:\n\n# Continuous: probability density\nd = Normal(0, 1)\npdf(d, 0.0)           # ≈ 0.3989\n\n# Discrete: probability mass\nd = Binomial(10, 0.5)\npdf(d, 5)             # ≈ 0.2461\n\n# Multiple points\npdf(Normal(0, 1), [-1.0, 0.0, 1.0])  # [0.242, 0.399, 0.242]\n\n","category":"section"},{"location":"api/core/#cdf-Cumulative-Distribution-Function","page":"Core Functions","title":"cdf - Cumulative Distribution Function","text":"Computes P(X ≤ x), the probability that the random variable is less than or equal to x.\n\ncdf(dist, x)\n\nArguments:\n\ndist: A distribution object\nx: Point(s) at which to evaluate\n\nReturns: Cumulative probability value(s)\n\nExamples:\n\nd = Normal(0, 1)\n\ncdf(d, 0.0)           # 0.5 (half of probability below mean)\ncdf(d, 1.96)          # ≈ 0.975\n\n# P(X > x) = 1 - cdf(x)\n1 - cdf(d, 1.96)      # ≈ 0.025\n\n# Multiple points\ncdf(d, [-1.96, 0, 1.96])  # [0.025, 0.5, 0.975]\n\n","category":"section"},{"location":"api/core/#quantile-Quantile-Function-(Inverse-CDF)","page":"Core Functions","title":"quantile - Quantile Function (Inverse CDF)","text":"Finds the value x such that P(X ≤ x) = p.\n\nquantile(dist, p)\n\nArguments:\n\ndist: A distribution object\np: Probability value(s), 0 ≤ p ≤ 1\n\nReturns: Quantile value(s)\n\nExamples:\n\nd = Normal(0, 1)\n\nquantile(d, 0.5)      # 0.0 (median)\nquantile(d, 0.975)    # ≈ 1.96\nquantile(d, 0.025)    # ≈ -1.96\n\n# Multiple quantiles\nquantile(d, [0.025, 0.5, 0.975])  # [-1.96, 0.0, 1.96]\n\n","category":"section"},{"location":"api/core/#R-Style-Shorthand-Functions","page":"Core Functions","title":"R-Style Shorthand Functions","text":"For users familiar with R's syntax, UniDist.jl provides shorthand aliases:\n\nShorthand Full Function R Equivalent\nd(dist, x) pdf(dist, x) dnorm(x)\np(dist, x) cdf(dist, x) pnorm(x)\nq(dist, p) quantile(dist, p) qnorm(p)\nr(dist, n) Random samples rnorm(n)\n\nExamples:\n\ndist = Normal(0, 1)\n\nd(dist, 0.0)          # Same as pdf(dist, 0.0)\np(dist, 1.96)         # Same as cdf(dist, 1.96)\nq(dist, 0.975)        # Same as quantile(dist, 0.975)\nr(dist, 100)          # 100 random samples\n\n","category":"section"},{"location":"api/core/#Distribution-Properties","page":"Core Functions","title":"Distribution Properties","text":"","category":"section"},{"location":"api/core/#mean-Expected-Value","page":"Core Functions","title":"mean - Expected Value","text":"Returns the mean (expected value) of the distribution.\n\nmean(dist)\n\nExamples:\n\nmean(Normal(5, 2))        # 5.0\nmean(Exponential(2))      # 2.0\nmean(Binomial(10, 0.3))   # 3.0\nmean(Poisson(4.5))        # 4.5\n\n","category":"section"},{"location":"api/core/#var-Variance","page":"Core Functions","title":"var - Variance","text":"Returns the variance of the distribution.\n\nvar(dist)\n\nExamples:\n\nvar(Normal(0, 2))         # 4.0 (σ²)\nvar(Exponential(2))       # 4.0 (θ²)\nvar(Binomial(10, 0.3))    # 2.1 (np(1-p))\nvar(Poisson(4.5))         # 4.5 (λ)\n\n","category":"section"},{"location":"api/core/#support-Distribution-Support","page":"Core Functions","title":"support - Distribution Support","text":"Returns the support (range of possible values) of the distribution.\n\nsupport(dist)\n\nReturns: A tuple (lower, upper) for continuous distributions, or the range for discrete distributions.\n\nExamples:\n\nsupport(Normal(0, 1))         # (-Inf, Inf)\nsupport(Exponential(1))       # (0, Inf)\nsupport(Beta(2, 3))           # (0, 1)\nsupport(Uniform(0, 10))       # (0, 10)\nsupport(Binomial(10, 0.5))    # Range or bounds\n\n","category":"section"},{"location":"api/core/#Random-Sampling","page":"Core Functions","title":"Random Sampling","text":"","category":"section"},{"location":"api/core/#r-Generate-Random-Samples","page":"Core Functions","title":"r - Generate Random Samples","text":"Generates random samples from the distribution.\n\nr(dist, n=1; rng=default_rng())\n\nArguments:\n\ndist: A distribution object\nn: Number of samples (default: 1)\nrng: Random number generator (optional)\n\nReturns: Array of random samples\n\nExamples:\n\nd = Normal(0, 1)\n\n# Single sample\nr(d)                  # e.g., 0.342\n\n# Multiple samples\nsamples = r(d, 1000)\nlength(samples)       # 1000\n\n# With specific RNG for reproducibility\nusing Random\nrng = MersenneTwister(42)\nr(d, 5; rng=rng)      # Reproducible samples\n\n","category":"section"},{"location":"api/core/#Vectorized-Operations","page":"Core Functions","title":"Vectorized Operations","text":"All core functions support vectorized operations over multiple input values:\n\nd = Normal(0, 1)\nxs = [-2.0, -1.0, 0.0, 1.0, 2.0]\n\n# PDF at multiple points\npdf(d, xs)            # [0.054, 0.242, 0.399, 0.242, 0.054]\n\n# CDF at multiple points\ncdf(d, xs)            # [0.023, 0.159, 0.5, 0.841, 0.977]\n\n# Multiple quantiles\nps = [0.1, 0.25, 0.5, 0.75, 0.9]\nquantile(d, ps)       # [-1.28, -0.67, 0.0, 0.67, 1.28]\n\n","category":"section"},{"location":"api/core/#Type-Hierarchy","page":"Core Functions","title":"Type Hierarchy","text":"UniDist.jl uses a type hierarchy to distinguish between distribution types:\n\nabstract type AbstractDistribution end\nabstract type DiscreteDistribution <: AbstractDistribution end\nabstract type ContinuousDistribution <: AbstractDistribution end\n\nThis allows for type-based dispatch and specialization:\n\n# Check distribution type\nd = Normal(0, 1)\nd isa ContinuousDistribution  # true\nd isa DiscreteDistribution    # false\n\nd = Binomial(10, 0.5)\nd isa DiscreteDistribution    # true","category":"section"},{"location":"getting-started/#getting-started","page":"Getting Started","title":"Getting Started","text":"This guide will help you get up and running with UniDist.jl quickly.","category":"section"},{"location":"getting-started/#Installation","page":"Getting Started","title":"Installation","text":"UniDist.jl can be installed using Julia's package manager:\n\nusing Pkg\nPkg.add(\"UniDist\")\n\nOr from the Julia REPL package mode (press ]):\n\npkg> add UniDist","category":"section"},{"location":"getting-started/#Basic-Usage","page":"Getting Started","title":"Basic Usage","text":"","category":"section"},{"location":"getting-started/#Creating-Distributions","page":"Getting Started","title":"Creating Distributions","text":"Distributions are created by calling their constructor with the appropriate parameters:\n\nusing UniDist\n\n# Normal distribution with mean=0 and standard deviation=1\nnormal = Normal(0.0, 1.0)\n\n# Exponential distribution with rate=2.0\nexponential = Exponential(2.0)\n\n# Binomial distribution with n=10 trials and p=0.5 probability\nbinomial = Binomial(10, 0.5)\n\n# Beta distribution with shape parameters α=2 and β=5\nbeta = Beta(2.0, 5.0)","category":"section"},{"location":"getting-started/#Computing-Probabilities","page":"Getting Started","title":"Computing Probabilities","text":"","category":"section"},{"location":"getting-started/#Probability-Density/Mass-Function","page":"Getting Started","title":"Probability Density/Mass Function","text":"Use pdf to compute the probability density (continuous) or probability mass (discrete):\n\n# P(X = x) for discrete, f(x) for continuous\npdf(Normal(0, 1), 0.0)      # ≈ 0.3989\npdf(Binomial(10, 0.5), 5)   # ≈ 0.2461","category":"section"},{"location":"getting-started/#Cumulative-Distribution-Function","page":"Getting Started","title":"Cumulative Distribution Function","text":"Use cdf to compute P(X ≤ x):\n\ncdf(Normal(0, 1), 1.96)     # ≈ 0.975\ncdf(Exponential(1.0), 1.0)  # ≈ 0.6321","category":"section"},{"location":"getting-started/#Quantile-Function","page":"Getting Started","title":"Quantile Function","text":"Use quantile to find the value x such that P(X ≤ x) = p:\n\nquantile(Normal(0, 1), 0.975)   # ≈ 1.96\nquantile(Normal(0, 1), 0.5)     # = 0.0 (median)","category":"section"},{"location":"getting-started/#Random-Sampling","page":"Getting Started","title":"Random Sampling","text":"Generate random samples using the r function:\n\n# Generate 1000 samples from a standard normal\nsamples = r(Normal(0, 1), 1000)\n\n# Generate a single sample\nsingle = r(Normal(0, 1))","category":"section"},{"location":"getting-started/#Distribution-Properties","page":"Getting Started","title":"Distribution Properties","text":"d = Normal(5.0, 2.0)\n\nmean(d)      # 5.0\nvar(d)       # 4.0\nsupport(d)   # (-Inf, Inf)","category":"section"},{"location":"getting-started/#R-Style-Shortcuts","page":"Getting Started","title":"R-Style Shortcuts","text":"If you're familiar with R, you can use the shorthand functions:\n\ndist = Normal(0, 1)\n\nd(dist, 0.0)   # Same as pdf(dist, 0.0)\np(dist, 1.96)  # Same as cdf(dist, 1.96)\nq(dist, 0.975) # Same as quantile(dist, 0.975)\nr(dist, 100)   # Random samples","category":"section"},{"location":"getting-started/#Working-with-Multiple-Values","page":"Getting Started","title":"Working with Multiple Values","text":"All functions support vectorized operations:\n\nd = Normal(0, 1)\n\n# Compute PDF at multiple points\npdf(d, [-2.0, -1.0, 0.0, 1.0, 2.0])\n\n# Compute CDF at multiple points\ncdf(d, [-1.96, 0.0, 1.96])\n\n# Compute multiple quantiles\nquantile(d, [0.025, 0.5, 0.975])","category":"section"},{"location":"getting-started/#Next-Steps","page":"Getting Started","title":"Next Steps","text":"Explore the full list of Continuous Distributions and Discrete Distributions\nLearn about Survival Analysis functions\nSee Statistical Intervals for confidence intervals and HDI\nCheck out the Basic Usage examples for real-world usage scenarios","category":"section"},{"location":"examples/basic-usage/#basic-usage","page":"Basic Usage","title":"Basic Usage","text":"This page demonstrates fundamental usage patterns for UniDist.jl.","category":"section"},{"location":"examples/basic-usage/#Creating-and-Using-Distributions","page":"Basic Usage","title":"Creating and Using Distributions","text":"","category":"section"},{"location":"examples/basic-usage/#Example-1:-Working-with-Normal-Distribution","page":"Basic Usage","title":"Example 1: Working with Normal Distribution","text":"using UniDist\n\n# Create a Normal distribution\nd = Normal(100, 15)  # IQ scores: mean=100, sd=15\n\n# What percentage of people have IQ > 130?\n1 - cdf(d, 130)       # ≈ 0.0228 (about 2.3%)\n\n# What percentage have IQ between 85 and 115?\ncdf(d, 115) - cdf(d, 85)  # ≈ 0.683 (about 68%)\n\n# What IQ score is at the 99th percentile?\nquantile(d, 0.99)     # ≈ 134.9\n\n# Generate 10 random IQ scores\nr(d, 10)","category":"section"},{"location":"examples/basic-usage/#Example-2:-Quality-Control-with-Binomial","page":"Basic Usage","title":"Example 2: Quality Control with Binomial","text":"using UniDist\n\n# A factory produces items with 2% defect rate\n# In a batch of 100 items, what's the probability of finding:\n\nd = Binomial(100, 0.02)\n\n# Exactly 2 defects?\npdf(d, 2)             # ≈ 0.273\n\n# At most 3 defects?\ncdf(d, 3)             # ≈ 0.858\n\n# More than 5 defects? (reject the batch)\n1 - cdf(d, 5)         # ≈ 0.015\n\n# Expected number of defects\nmean(d)               # 2.0","category":"section"},{"location":"examples/basic-usage/#Example-3:-Waiting-Times-with-Exponential","page":"Basic Usage","title":"Example 3: Waiting Times with Exponential","text":"using UniDist\n\n# Customers arrive on average every 5 minutes\nd = Exponential(5.0)\n\n# Probability of waiting more than 10 minutes\nsf(d, 10)             # ≈ 0.135\n\n# Probability of waiting less than 2 minutes\ncdf(d, 2)             # ≈ 0.330\n\n# Median waiting time\nquantile(d, 0.5)      # ≈ 3.47 minutes\n\n","category":"section"},{"location":"examples/basic-usage/#Computing-Multiple-Values","page":"Basic Usage","title":"Computing Multiple Values","text":"","category":"section"},{"location":"examples/basic-usage/#Batch-Probability-Calculations","page":"Basic Usage","title":"Batch Probability Calculations","text":"using UniDist\n\nd = Normal(0, 1)\n\n# PDF at multiple points\nxs = -3:0.5:3\ndensities = pdf(d, collect(xs))\n\n# Print as a table\nprintln(\"x\\t\\tpdf(x)\")\nfor (x, p) in zip(xs, densities)\n    println(\"$x\\t\\t$(round(p, digits=4))\")\nend","category":"section"},{"location":"examples/basic-usage/#Multiple-Quantiles","page":"Basic Usage","title":"Multiple Quantiles","text":"using UniDist\n\nd = Normal(100, 15)\n\n# Common percentiles\npercentiles = [0.01, 0.05, 0.10, 0.25, 0.50, 0.75, 0.90, 0.95, 0.99]\nvalues = quantile(d, percentiles)\n\nprintln(\"Percentile\\tValue\")\nfor (p, v) in zip(percentiles, values)\n    println(\"$(Int(p*100))%\\t\\t$(round(v, digits=1))\")\nend\n\n","category":"section"},{"location":"examples/basic-usage/#Distribution-Properties","page":"Basic Usage","title":"Distribution Properties","text":"","category":"section"},{"location":"examples/basic-usage/#Summary-Statistics","page":"Basic Usage","title":"Summary Statistics","text":"using UniDist\n\ndistributions = [\n    (\"Normal(0,1)\", Normal(0, 1)),\n    (\"Exponential(2)\", Exponential(2)),\n    (\"Gamma(2,3)\", Gamma(2, 3)),\n    (\"Beta(2,5)\", Beta(2, 5)),\n]\n\nprintln(\"Distribution\\t\\tMean\\tVariance\\tSupport\")\nfor (name, d) in distributions\n    m = round(mean(d), digits=3)\n    v = round(var(d), digits=3)\n    s = support(d)\n    println(\"$name\\t\\t$m\\t$v\\t\\t$s\")\nend\n\n","category":"section"},{"location":"examples/basic-usage/#Probability-Calculations","page":"Basic Usage","title":"Probability Calculations","text":"","category":"section"},{"location":"examples/basic-usage/#Finding-Probabilities","page":"Basic Usage","title":"Finding Probabilities","text":"using UniDist\n\n# Exam scores follow Normal(75, 10)\nscores = Normal(75, 10)\n\n# P(score ≥ 90) - probability of an A\nprob_A = 1 - cdf(scores, 90)\nprintln(\"P(A grade): $(round(prob_A * 100, digits=1))%\")\n\n# P(60 ≤ score < 70) - probability of a D\nprob_D = cdf(scores, 70) - cdf(scores, 60)\nprintln(\"P(D grade): $(round(prob_D * 100, digits=1))%\")\n\n# P(score < 50) - probability of failing\nprob_fail = cdf(scores, 50)\nprintln(\"P(Fail): $(round(prob_fail * 100, digits=1))%\")","category":"section"},{"location":"examples/basic-usage/#Inverse-Problems","page":"Basic Usage","title":"Inverse Problems","text":"using UniDist\n\n# What score do you need to be in the top 10%?\nscores = Normal(75, 10)\ntop_10_cutoff = quantile(scores, 0.90)\nprintln(\"Top 10% cutoff: $(round(top_10_cutoff, digits=1))\")\n\n# What score is the median?\nmedian_score = quantile(scores, 0.50)\nprintln(\"Median score: $median_score\")\n\n","category":"section"},{"location":"examples/basic-usage/#Working-with-Discrete-Distributions","page":"Basic Usage","title":"Working with Discrete Distributions","text":"","category":"section"},{"location":"examples/basic-usage/#Dice-Rolling","page":"Basic Usage","title":"Dice Rolling","text":"using UniDist\n\n# Fair die\ndie = DiscreteUniform(1, 6)\n\n# Probability of rolling a 6\npdf(die, 6)           # ≈ 0.167\n\n# Probability of rolling ≤ 3\ncdf(die, 3)           # 0.5\n\n# Expected value\nmean(die)             # 3.5","category":"section"},{"location":"examples/basic-usage/#Counting-Successes","page":"Basic Usage","title":"Counting Successes","text":"using UniDist\n\n# Flip a fair coin 10 times\nflips = Binomial(10, 0.5)\n\n# Probability of exactly 5 heads\npdf(flips, 5)         # ≈ 0.246\n\n# Probability of at least 7 heads\n1 - cdf(flips, 6)     # ≈ 0.172\n\n# Most likely outcome\n# (find k that maximizes pdf)\nprobs = [pdf(flips, k) for k in 0:10]\nmode = argmax(probs) - 1  # 5\n\n","category":"section"},{"location":"examples/basic-usage/#Random-Sampling","page":"Basic Usage","title":"Random Sampling","text":"","category":"section"},{"location":"examples/basic-usage/#Basic-Sampling","page":"Basic Usage","title":"Basic Sampling","text":"using UniDist\n\nd = Normal(0, 1)\n\n# Single sample\nx = r(d)\n\n# Multiple samples\nsamples = r(d, 1000)\n\n# Sample statistics\nsample_mean = sum(samples) / length(samples)\nsample_var = sum((x - sample_mean)^2 for x in samples) / (length(samples) - 1)\n\nprintln(\"Sample mean: $(round(sample_mean, digits=3)) (true: 0)\")\nprintln(\"Sample var: $(round(sample_var, digits=3)) (true: 1)\")","category":"section"},{"location":"examples/basic-usage/#Reproducible-Sampling","page":"Basic Usage","title":"Reproducible Sampling","text":"using UniDist\nusing Random\n\nd = Normal(0, 1)\n\n# Set seed for reproducibility\nrng = MersenneTwister(42)\n\n# These will always be the same\nsamples1 = r(d, 5; rng=MersenneTwister(42))\nsamples2 = r(d, 5; rng=MersenneTwister(42))\n\nsamples1 == samples2  # true\n\n","category":"section"},{"location":"examples/basic-usage/#Combining-Operations","page":"Basic Usage","title":"Combining Operations","text":"","category":"section"},{"location":"examples/basic-usage/#Monte-Carlo-Estimation","page":"Basic Usage","title":"Monte Carlo Estimation","text":"using UniDist\n\n# Estimate P(X > Y) where X ~ Normal(5, 2), Y ~ Normal(4, 1)\nX = Normal(5, 2)\nY = Normal(4, 1)\n\nn = 100000\nx_samples = r(X, n)\ny_samples = r(Y, n)\n\nprob_x_greater = sum(x_samples .> y_samples) / n\nprintln(\"P(X > Y) ≈ $(round(prob_x_greater, digits=3))\")","category":"section"},{"location":"examples/basic-usage/#Distribution-Comparison","page":"Basic Usage","title":"Distribution Comparison","text":"using UniDist\n\n# Compare Poisson and Normal approximation\nλ = 50\npoisson = Poisson(λ)\nnormal_approx = Normal(λ, sqrt(λ))\n\n# Compare CDFs at various points\npoints = [40, 45, 50, 55, 60]\nprintln(\"x\\tPoisson\\t\\tNormal\")\nfor x in points\n    p_pois = round(cdf(poisson, x), digits=4)\n    p_norm = round(cdf(normal_approx, x), digits=4)\n    println(\"$x\\t$p_pois\\t\\t$p_norm\")\nend","category":"section"},{"location":"examples/bayesian/#bayesian-inference","page":"Bayesian Inference","title":"Bayesian Inference","text":"This page demonstrates using UniDist.jl for Bayesian statistical analysis with conjugate priors.","category":"section"},{"location":"examples/bayesian/#Introduction-to-Bayesian-Analysis","page":"Bayesian Inference","title":"Introduction to Bayesian Analysis","text":"Bayesian inference combines prior beliefs with observed data to produce posterior distributions:\n\nPosterior ∝ Likelihood × Prior\n\nUniDist.jl provides the distributions needed for common conjugate analysis.\n\n","category":"section"},{"location":"examples/bayesian/#Beta-Binomial-Model","page":"Bayesian Inference","title":"Beta-Binomial Model","text":"The Beta distribution is conjugate to the Binomial likelihood, making it ideal for estimating proportions.","category":"section"},{"location":"examples/bayesian/#Estimating-Success-Probability","page":"Bayesian Inference","title":"Estimating Success Probability","text":"using UniDist\n\n# Scenario: Estimating website conversion rate\n# Prior belief: ~10% conversion, somewhat uncertain\n\n# Prior: Beta(2, 18) → mean = 2/20 = 0.10\nprior = Beta(2, 18)\n\nprintln(\"Prior:\")\nprintln(\"  Mean: $(round(mean(prior), digits=3))\")\nlo, hi = hdi(prior, 0.95)\nprintln(\"  95% HDI: [$(round(lo, digits=3)), $(round(hi, digits=3))]\")\n\n# Data: 15 conversions out of 100 visitors\nsuccesses = 15\nfailures = 85\n\n# Posterior: Beta(α + successes, β + failures)\nposterior = Beta(2 + successes, 18 + failures)\n\nprintln(\"\\nPosterior (after 100 visitors, 15 conversions):\")\nprintln(\"  Mean: $(round(mean(posterior), digits=3))\")\nlo, hi = hdi(posterior, 0.95)\nprintln(\"  95% HDI: [$(round(lo, digits=3)), $(round(hi, digits=3))]\")\n\n# Probability conversion rate > 10%\np_above_10 = 1 - cdf(posterior, 0.10)\nprintln(\"  P(rate > 10%): $(round(p_above_10 * 100, digits=1))%\")","category":"section"},{"location":"examples/bayesian/#A/B-Testing","page":"Bayesian Inference","title":"A/B Testing","text":"using UniDist\n\n# Compare two versions: A (control) vs B (treatment)\n# Prior: Beta(1, 1) = Uniform (non-informative)\n\n# Version A: 45 conversions out of 500\npost_A = Beta(1 + 45, 1 + 455)\n\n# Version B: 62 conversions out of 500\npost_B = Beta(1 + 62, 1 + 438)\n\nprintln(\"Version A conversion rate:\")\nprintln(\"  Mean: $(round(mean(post_A) * 100, digits=2))%\")\nlo, hi = hdi(post_A, 0.95)\nprintln(\"  95% HDI: [$(round(lo * 100, digits=2))%, $(round(hi * 100, digits=2))%]\")\n\nprintln(\"\\nVersion B conversion rate:\")\nprintln(\"  Mean: $(round(mean(post_B) * 100, digits=2))%\")\nlo, hi = hdi(post_B, 0.95)\nprintln(\"  95% HDI: [$(round(lo * 100, digits=2))%, $(round(hi * 100, digits=2))%]\")\n\n# Monte Carlo: P(B > A)\nn_samples = 100000\nsamples_A = r(post_A, n_samples)\nsamples_B = r(post_B, n_samples)\np_B_better = sum(samples_B .> samples_A) / n_samples\n\nprintln(\"\\nP(B > A): $(round(p_B_better * 100, digits=1))%\")\n\n# Expected lift\nlift_samples = (samples_B .- samples_A) ./ samples_A\nmean_lift = sum(lift_samples) / n_samples\nprintln(\"Expected lift: $(round(mean_lift * 100, digits=1))%\")\n\n","category":"section"},{"location":"examples/bayesian/#Gamma-Poisson-Model","page":"Bayesian Inference","title":"Gamma-Poisson Model","text":"The Gamma distribution is conjugate to the Poisson likelihood, useful for estimating rates.","category":"section"},{"location":"examples/bayesian/#Estimating-Event-Rate","page":"Bayesian Inference","title":"Estimating Event Rate","text":"using UniDist\n\n# Scenario: Estimating customer support tickets per day\n# Prior: Gamma(2, 10) → mean = 20 tickets/day, moderate uncertainty\n\nprior = Gamma(2, 10)\n\nprintln(\"Prior:\")\nprintln(\"  Mean: $(round(mean(prior), digits=1)) tickets/day\")\nlo, hi = hdi(prior, 0.95)\nprintln(\"  95% HDI: [$(round(lo, digits=1)), $(round(hi, digits=1))]\")\n\n# Data: Observed 156 tickets over 7 days\ntotal_count = 156\nn_days = 7\n\n# Posterior: Gamma(α + total_count, β / (1 + n_days * β))\n# Or equivalently with rate parameterization\nα_post = 2 + total_count\nθ_post = 10 / (1 + n_days * 0.1)  # Adjust scale\n\n# Simpler: Gamma(α + Σx, θ/(1 + n*θ)) where θ is scale\nposterior = Gamma(α_post, θ_post)\n\nprintln(\"\\nPosterior (after observing $total_count tickets in $n_days days):\")\nprintln(\"  Mean: $(round(mean(posterior), digits=1)) tickets/day\")\nlo, hi = hdi(posterior, 0.95)\nprintln(\"  95% HDI: [$(round(lo, digits=1)), $(round(hi, digits=1))]\")\n\n","category":"section"},{"location":"examples/bayesian/#Normal-Normal-Model","page":"Bayesian Inference","title":"Normal-Normal Model","text":"With known variance, the Normal distribution is conjugate to itself.","category":"section"},{"location":"examples/bayesian/#Estimating-Population-Mean","page":"Bayesian Inference","title":"Estimating Population Mean","text":"using UniDist\n\n# Scenario: Estimating average customer spending\n# Prior belief: $50 average, uncertain (σ_prior = $10)\n# Known population σ = $20\n\nprior_mean = 50.0\nprior_sd = 10.0\nknown_sd = 20.0\n\nprior = Normal(prior_mean, prior_sd)\n\nprintln(\"Prior:\")\nprintln(\"  Mean: \\$$(prior_mean)\")\nlo, hi = interval(prior, 0.05)\nprintln(\"  95% CI: [\\$$(round(lo, digits=2)), \\$$(round(hi, digits=2))]\")\n\n# Data: n=25 customers, sample mean = $58\nn = 25\nsample_mean = 58.0\n\n# Posterior parameters\n# Precision-weighted combination\nprior_precision = 1 / prior_sd^2\ndata_precision = n / known_sd^2\ntotal_precision = prior_precision + data_precision\n\nposterior_mean = (prior_precision * prior_mean + data_precision * sample_mean) / total_precision\nposterior_sd = sqrt(1 / total_precision)\n\nposterior = Normal(posterior_mean, posterior_sd)\n\nprintln(\"\\nPosterior (after n=$n observations):\")\nprintln(\"  Mean: \\$$(round(posterior_mean, digits=2))\")\nlo, hi = interval(posterior, 0.05)\nprintln(\"  95% CI: [\\$$(round(lo, digits=2)), \\$$(round(hi, digits=2))]\")\n\n# Probability mean > $55\np_above_55 = 1 - cdf(posterior, 55)\nprintln(\"  P(μ > \\$55): $(round(p_above_55 * 100, digits=1))%\")\n\n","category":"section"},{"location":"examples/bayesian/#Sequential-Updating","page":"Bayesian Inference","title":"Sequential Updating","text":"Bayesian inference naturally supports sequential data processing.\n\nusing UniDist\n\n# Start with weakly informative prior\nprior = Beta(1, 1)\n\nprintln(\"Sequential Bayesian updating for proportion:\")\nprintln(\"=\" ^ 50)\n\n# Observe data in batches\nbatches = [(5, 10), (8, 15), (12, 20), (7, 12)]  # (successes, trials)\n\ncurrent = prior\ntotal_successes = 0\ntotal_trials = 0\n\nprintln(\"\\nBatch\\tData\\t\\tPosterior Mean\\t95% HDI\")\nprintln(\"-\" ^ 50)\n\nfor (i, (s, n)) in enumerate(batches)\n    total_successes += s\n    total_trials += n\n\n    # Update posterior\n    current = Beta(1 + total_successes, 1 + total_trials - total_successes)\n\n    lo, hi = hdi(current, 0.95)\n    println(\"$i\\t$s/$n\\t\\t$(round(mean(current), digits=3))\\t\\t[$(round(lo, digits=3)), $(round(hi, digits=3))]\")\nend\n\nprintln(\"-\" ^ 50)\nprintln(\"Final: $(total_successes)/$(total_trials) total\")\n\n","category":"section"},{"location":"examples/bayesian/#Predictive-Distributions","page":"Bayesian Inference","title":"Predictive Distributions","text":"","category":"section"},{"location":"examples/bayesian/#Posterior-Predictive-for-Binomial","page":"Bayesian Inference","title":"Posterior Predictive for Binomial","text":"using UniDist\n\n# After observing data, predict future observations\n# Posterior: Beta(20, 80) for success probability\n\nposterior = Beta(20, 80)\n\n# Predict: In next 50 trials, how many successes?\n# This is Beta-Binomial\n\nn_future = 50\n\n# Monte Carlo prediction\nn_samples = 10000\npredictions = Int[]\n\nfor _ in 1:n_samples\n    # Sample p from posterior\n    p = r(posterior)[1]\n    # Sample outcome from Binomial(n_future, p)\n    k = r(Binomial(n_future, p))[1]\n    push!(predictions, k)\nend\n\nmean_pred = sum(predictions) / n_samples\nlo = sort(predictions)[Int(0.025 * n_samples)]\nhi = sort(predictions)[Int(0.975 * n_samples)]\n\nprintln(\"Posterior predictive for next $n_future trials:\")\nprintln(\"  Expected successes: $(round(mean_pred, digits=1))\")\nprintln(\"  95% prediction interval: [$lo, $hi]\")\n\n","category":"section"},{"location":"examples/bayesian/#Model-Comparison","page":"Bayesian Inference","title":"Model Comparison","text":"","category":"section"},{"location":"examples/bayesian/#Bayes-Factor-Approximation","page":"Bayesian Inference","title":"Bayes Factor Approximation","text":"using UniDist\n\n# Compare two models for coin fairness\n# M1: Fair coin (p = 0.5)\n# M2: Biased coin (p ~ Beta(1, 1))\n\n# Data: 7 heads out of 10 flips\n\nk = 7  # successes\nn = 10 # trials\n\n# Likelihood under M1 (point hypothesis p = 0.5)\nL1 = pdf(Binomial(n, 0.5), k)\n\n# Marginal likelihood under M2 (integrated over prior)\n# For Beta(1,1) prior and Binomial likelihood:\n# P(data | M2) = B(k+1, n-k+1) / B(1, 1) = 1/(n+1)\nL2 = 1 / (n + 1)\n\n# Bayes Factor\nBF_12 = L1 / L2\n\nprintln(\"Data: $k heads out of $n flips\")\nprintln(\"\\nP(data | fair coin): $(round(L1, digits=4))\")\nprintln(\"P(data | biased coin): $(round(L2, digits=4))\")\nprintln(\"\\nBayes Factor (fair vs biased): $(round(BF_12, digits=2))\")\n\nif BF_12 > 3\n    println(\"Evidence favors fair coin\")\nelseif BF_12 < 1/3\n    println(\"Evidence favors biased coin\")\nelse\n    println(\"Evidence is inconclusive\")\nend\n\n","category":"section"},{"location":"examples/bayesian/#Credible-Intervals-vs-Confidence-Intervals","page":"Bayesian Inference","title":"Credible Intervals vs Confidence Intervals","text":"using UniDist\n\n# Bayesian credible interval\n# Posterior for proportion after observing 30/100\n\nposterior = Beta(31, 71)  # Beta(1+30, 1+70) with uniform prior\n\n# 95% Equal-tailed credible interval\neq_lo, eq_hi = interval(posterior, 0.05)\n\n# 95% Highest Density Interval\nhdi_lo, hdi_hi = hdi(posterior, 0.95)\n\nprintln(\"Posterior: Beta(31, 71)\")\nprintln(\"  Mean: $(round(mean(posterior), digits=3))\")\nprintln()\nprintln(\"95% Equal-tailed CI: [$(round(eq_lo, digits=3)), $(round(eq_hi, digits=3))]\")\nprintln(\"95% HDI: [$(round(hdi_lo, digits=3)), $(round(hdi_hi, digits=3))]\")\nprintln()\nprintln(\"Interpretation:\")\nprintln(\"  There is a 95% probability that the true proportion\")\nprintln(\"  lies within the credible interval, given the data and prior.\")\n\n","category":"section"},{"location":"examples/bayesian/#ROPE-Analysis-(Region-of-Practical-Equivalence)","page":"Bayesian Inference","title":"ROPE Analysis (Region of Practical Equivalence)","text":"using UniDist\n\n# Is the effect practically equivalent to zero?\n# Define ROPE as [-0.1, 0.1]\n\nposterior = Normal(0.08, 0.05)  # Effect size posterior\n\nrope_lo = -0.1\nrope_hi = 0.1\n\n# Probability mass in ROPE\np_in_rope = cdf(posterior, rope_hi) - cdf(posterior, rope_lo)\n\n# Probability below ROPE (negative effect)\np_below = cdf(posterior, rope_lo)\n\n# Probability above ROPE (positive effect)\np_above = 1 - cdf(posterior, rope_hi)\n\nprintln(\"Posterior: Normal(0.08, 0.05)\")\nprintln(\"ROPE: [$rope_lo, $rope_hi]\")\nprintln()\nprintln(\"P(effect in ROPE): $(round(p_in_rope * 100, digits=1))%\")\nprintln(\"P(effect < ROPE): $(round(p_below * 100, digits=1))%\")\nprintln(\"P(effect > ROPE): $(round(p_above * 100, digits=1))%\")\nprintln()\n\nif p_in_rope > 0.95\n    println(\"Decision: Accept practical equivalence\")\nelseif p_above > 0.95 || p_below > 0.95\n    println(\"Decision: Reject practical equivalence\")\nelse\n    println(\"Decision: Undecided (need more data)\")\nend","category":"section"},{"location":"distributions/discrete/#discrete-distributions","page":"Discrete Distributions","title":"Discrete Distributions","text":"UniDist.jl provides 19 discrete probability distributions. This page documents each distribution with its parameters, support, and usage examples.","category":"section"},{"location":"distributions/discrete/#Common-Distributions","page":"Discrete Distributions","title":"Common Distributions","text":"","category":"section"},{"location":"distributions/discrete/#Bernoulli","page":"Discrete Distributions","title":"Bernoulli","text":"Single trial with two outcomes (success/failure).\n\nBernoulli(p)  # p = probability of success\n\nParameters:\n\np: Probability of success, 0 ≤ p ≤ 1\n\nSupport: {0, 1}\n\nExample:\n\nd = Bernoulli(0.7)\n\npdf(d, 1)             # 0.7 (probability of success)\npdf(d, 0)             # 0.3 (probability of failure)\ncdf(d, 0)             # 0.3\nmean(d)               # 0.7\nvar(d)                # 0.21\n\nUse cases: Coin flips, yes/no outcomes, binary classification.\n\n","category":"section"},{"location":"distributions/discrete/#Binomial","page":"Discrete Distributions","title":"Binomial","text":"Number of successes in n independent Bernoulli trials.\n\nBinomial(n, p)  # n = trials, p = success probability\n\nParameters:\n\nn: Number of trials, n ≥ 0\np: Probability of success, 0 ≤ p ≤ 1\n\nSupport: {0, 1, 2, ..., n}\n\nExample:\n\nd = Binomial(10, 0.5)\n\npdf(d, 5)             # ≈ 0.246 (probability of exactly 5 successes)\ncdf(d, 5)             # ≈ 0.623 (probability of at most 5 successes)\nmean(d)               # 5.0\nvar(d)                # 2.5\n\nUse cases: Quality control, survey sampling, A/B testing, clinical trials.\n\n","category":"section"},{"location":"distributions/discrete/#Poisson","page":"Discrete Distributions","title":"Poisson","text":"Number of events in a fixed interval when events occur at constant rate.\n\nPoisson(λ)  # λ = rate (expected count)\n\nParameters:\n\nλ (lambda): Rate parameter, λ > 0\n\nSupport: {0, 1, 2, 3, ...}\n\nExample:\n\nd = Poisson(3.0)\n\npdf(d, 0)             # ≈ 0.050 (P(X = 0))\npdf(d, 3)             # ≈ 0.224 (P(X = 3))\ncdf(d, 3)             # ≈ 0.647\nmean(d)               # 3.0\nvar(d)                # 3.0\n\nUse cases: Customer arrivals, website visits, defect counts, rare events.\n\n","category":"section"},{"location":"distributions/discrete/#Geometric","page":"Discrete Distributions","title":"Geometric","text":"Number of failures before first success.\n\nGeometric(p)  # p = success probability\n\nParameters:\n\np: Probability of success, 0 < p ≤ 1\n\nSupport: {0, 1, 2, 3, ...}\n\nExample:\n\nd = Geometric(0.5)\n\npdf(d, 0)             # 0.5 (success on first trial)\npdf(d, 1)             # 0.25 (one failure, then success)\npdf(d, 2)             # 0.125\nmean(d)               # 1.0 (expected failures before success)\n\nUse cases: Number of trials until success, waiting times, reliability testing.\n\n","category":"section"},{"location":"distributions/discrete/#DiscreteUniform","page":"Discrete Distributions","title":"DiscreteUniform","text":"All integers in [a, b] equally likely.\n\nDiscreteUniform(a, b)  # a = min, b = max\n\nParameters:\n\na: Minimum value (integer)\nb: Maximum value (integer), b ≥ a\n\nSupport: {a, a+1, ..., b}\n\nExample:\n\nd = DiscreteUniform(1, 6)  # Fair die\n\npdf(d, 3)             # ≈ 0.167\ncdf(d, 3)             # 0.5\nmean(d)               # 3.5\n\nUse cases: Dice rolls, random selection, lottery numbers.\n\n","category":"section"},{"location":"distributions/discrete/#Count-Distributions","page":"Discrete Distributions","title":"Count Distributions","text":"","category":"section"},{"location":"distributions/discrete/#Pascal-(Negative-Binomial)","page":"Discrete Distributions","title":"Pascal (Negative Binomial)","text":"Number of failures before r successes.\n\nPascal(r, p)  # r = successes needed, p = success probability\n\nParameters:\n\nr: Number of successes required, r > 0\np: Probability of success, 0 < p ≤ 1\n\nSupport: {0, 1, 2, 3, ...}\n\nExample:\n\nd = Pascal(3, 0.5)\n\npdf(d, 2)             # Probability of 2 failures before 3 successes\nmean(d)               # r(1-p)/p\n\nUse cases: Overdispersed count data, number of trials until r successes.\n\n","category":"section"},{"location":"distributions/discrete/#GammaPoisson-(Negative-Binomial-alternative-parameterization)","page":"Discrete Distributions","title":"GammaPoisson (Negative Binomial alternative parameterization)","text":"Poisson distribution with Gamma-distributed rate.\n\nGammaPoisson(r, p)\n\nUse cases: Modeling count data with overdispersion.\n\n","category":"section"},{"location":"distributions/discrete/#Hypergeometric","page":"Discrete Distributions","title":"Hypergeometric","text":"Sampling without replacement from a finite population.\n\nHypergeometric(N, K, n)  # N = population, K = successes in population, n = draws\n\nParameters:\n\nN: Population size\nK: Number of success states in population\nn: Number of draws\n\nSupport: {max(0, n+K-N), ..., min(n, K)}\n\nExample:\n\n# Drawing 5 cards, how many aces?\nd = Hypergeometric(52, 4, 5)\n\npdf(d, 0)             # Probability of no aces\npdf(d, 1)             # Probability of exactly 1 ace\nmean(d)               # n * K / N\n\nUse cases: Quality sampling, card games, capture-recapture studies.\n\n","category":"section"},{"location":"distributions/discrete/#NegativeHypergeometric","page":"Discrete Distributions","title":"NegativeHypergeometric","text":"NegativeHypergeometric(N, K, r)\n\n","category":"section"},{"location":"distributions/discrete/#Special-Distributions","page":"Discrete Distributions","title":"Special Distributions","text":"","category":"section"},{"location":"distributions/discrete/#BetaBinomial","page":"Discrete Distributions","title":"BetaBinomial","text":"Binomial with Beta-distributed success probability.\n\nBetaBinomial(n, α, β)  # n = trials, α, β = Beta parameters\n\nParameters:\n\nn: Number of trials\nα (alpha): Beta shape parameter, α > 0\nβ (beta): Beta shape parameter, β > 0\n\nSupport: {0, 1, 2, ..., n}\n\nExample:\n\nd = BetaBinomial(10, 2, 3)\n\npdf(d, 5)             # Probability of 5 successes\nmean(d)               # n * α / (α + β)\n\nUse cases: Overdispersed binomial data, Bayesian inference.\n\n","category":"section"},{"location":"distributions/discrete/#BetaPascal","page":"Discrete Distributions","title":"BetaPascal","text":"Pascal distribution with Beta-distributed success probability.\n\nBetaPascal(r, α, β)\n\n","category":"section"},{"location":"distributions/discrete/#Polya-(Beta-Binomial-alternative)","page":"Discrete Distributions","title":"Polya (Beta-Binomial alternative)","text":"Polya(n, α, β)\n\n","category":"section"},{"location":"distributions/discrete/#Rank-and-Order-Distributions","page":"Discrete Distributions","title":"Rank and Order Distributions","text":"","category":"section"},{"location":"distributions/discrete/#Benford","page":"Discrete Distributions","title":"Benford","text":"Distribution of first digits in many real-world datasets.\n\nBenford()\n\nSupport: {1, 2, 3, ..., 9}\n\nExample:\n\nd = Benford()\n\npdf(d, 1)             # ≈ 0.301 (30.1% start with 1)\npdf(d, 9)             # ≈ 0.046 (4.6% start with 9)\n\nUse cases: Fraud detection, data validation, forensic accounting.\n\n","category":"section"},{"location":"distributions/discrete/#Zipf","page":"Discrete Distributions","title":"Zipf","text":"Power-law distribution for ranked data.\n\nZipf(s, N)  # s = exponent, N = number of elements\n\nParameters:\n\ns: Exponent parameter, s > 0\nN: Number of elements\n\nSupport: {1, 2, 3, ..., N}\n\nExample:\n\nd = Zipf(1.0, 100)\n\npdf(d, 1)             # Probability of rank 1\npdf(d, 2)             # Probability of rank 2 (about half of rank 1)\n\nUse cases: Word frequencies, city populations, website popularity.\n\n","category":"section"},{"location":"distributions/discrete/#Zeta-(Zipf-with-infinite-support)","page":"Discrete Distributions","title":"Zeta (Zipf with infinite support)","text":"Zeta(s)  # s = exponent\n\nParameters:\n\ns: Exponent parameter, s > 1\n\nSupport: {1, 2, 3, ...}\n\nUse cases: Power-law phenomena with unbounded support.\n\n","category":"section"},{"location":"distributions/discrete/#Logarithm-(Logarithmic-Series)","page":"Discrete Distributions","title":"Logarithm (Logarithmic Series)","text":"Logarithm(p)  # p = parameter\n\nParameters:\n\np: Parameter, 0 < p < 1\n\nSupport: {1, 2, 3, ...}\n\nUse cases: Species abundance, word frequency.\n\n","category":"section"},{"location":"distributions/discrete/#Other-Discrete-Distributions","page":"Discrete Distributions","title":"Other Discrete Distributions","text":"","category":"section"},{"location":"distributions/discrete/#DiscreteWeibull","page":"Discrete Distributions","title":"DiscreteWeibull","text":"Discrete analog of Weibull distribution.\n\nDiscreteWeibull(q, β)  # q = parameter, β = shape\n\nSupport: {0, 1, 2, 3, ...}\n\nUse cases: Discrete lifetime data, count-based reliability.\n\n","category":"section"},{"location":"distributions/discrete/#PowerSeries","page":"Discrete Distributions","title":"PowerSeries","text":"General power series distribution.\n\nPowerSeries(f, θ)  # f = coefficient function, θ = parameter\n\n","category":"section"},{"location":"distributions/discrete/#Rectangular","page":"Discrete Distributions","title":"Rectangular","text":"Alias for DiscreteUniform.\n\nRectangular(a, b)\n\n","category":"section"},{"location":"distributions/discrete/#Usage-Examples","page":"Discrete Distributions","title":"Usage Examples","text":"","category":"section"},{"location":"distributions/discrete/#Comparing-Distributions","page":"Discrete Distributions","title":"Comparing Distributions","text":"using UniDist\n\n# Compare Binomial approximation to Poisson\nn, p = 100, 0.03\nbinomial = Binomial(n, p)\npoisson = Poisson(n * p)\n\nfor k in 0:10\n    println(\"k=$k: Binomial=$(round(pdf(binomial, k), digits=4)), Poisson=$(round(pdf(poisson, k), digits=4))\")\nend","category":"section"},{"location":"distributions/discrete/#Cumulative-Probabilities","page":"Discrete Distributions","title":"Cumulative Probabilities","text":"d = Poisson(5.0)\n\n# P(X ≤ 3)\ncdf(d, 3)\n\n# P(X > 3) = 1 - P(X ≤ 3)\n1 - cdf(d, 3)\n\n# P(2 ≤ X ≤ 5)\ncdf(d, 5) - cdf(d, 1)","category":"section"},{"location":"distributions/discrete/#Finding-Quantiles","page":"Discrete Distributions","title":"Finding Quantiles","text":"d = Binomial(20, 0.5)\n\n# Find the 95th percentile\nquantile(d, 0.95)\n\n# Find the median\nquantile(d, 0.5)","category":"section"},{"location":"examples/vectorized/#vectorized-operations","page":"Vectorized Operations","title":"Vectorized Operations","text":"UniDist.jl supports vectorized parameters, allowing efficient batch computations across multiple distribution configurations.","category":"section"},{"location":"examples/vectorized/#Vectorized-Distribution-Parameters","page":"Vectorized Operations","title":"Vectorized Distribution Parameters","text":"","category":"section"},{"location":"examples/vectorized/#Multiple-Means","page":"Vectorized Operations","title":"Multiple Means","text":"using UniDist\n\n# Create Normal distributions with different means\n# All with σ = 1\nd = Normal([0.0, 1.0, 2.0, 3.0], 1.0)\n\n# Evaluate PDF at x = 1 for all distributions\npdf(d, 1.0)\n# Returns: [0.242, 0.399, 0.242, 0.054]\n# (density at x=1 for each mean)","category":"section"},{"location":"examples/vectorized/#Multiple-Standard-Deviations","page":"Vectorized Operations","title":"Multiple Standard Deviations","text":"using UniDist\n\n# Normal(0, σ) for different σ values\nd = Normal(0.0, [0.5, 1.0, 2.0, 4.0])\n\n# Compare densities at x = 0\npdf(d, 0.0)\n# Higher density for smaller σ (more concentrated)","category":"section"},{"location":"examples/vectorized/#Grid-of-Parameters","page":"Vectorized Operations","title":"Grid of Parameters","text":"using UniDist\n\n# Create a grid of Beta distributions\nαs = [0.5, 1.0, 2.0, 5.0]\nβs = [0.5, 1.0, 2.0, 5.0]\n\n# Evaluate mean for each combination\nfor α in αs\n    for β in βs\n        d = Beta(α, β)\n        m = mean(d)\n        println(\"Beta($α, $β): mean = $(round(m, digits=3))\")\n    end\nend\n\n","category":"section"},{"location":"examples/vectorized/#Vectorized-Evaluation-Points","page":"Vectorized Operations","title":"Vectorized Evaluation Points","text":"","category":"section"},{"location":"examples/vectorized/#PDF-at-Multiple-Points","page":"Vectorized Operations","title":"PDF at Multiple Points","text":"using UniDist\n\nd = Normal(0, 1)\n\n# Evaluate at many points simultaneously\nxs = range(-4, 4, length=100)\ndensities = pdf(d, collect(xs))\n\n# Find the maximum density\nmax_density = maximum(densities)\nmax_idx = argmax(densities)\nprintln(\"Maximum density $(round(max_density, digits=4)) at x = $(xs[max_idx])\")","category":"section"},{"location":"examples/vectorized/#CDF-at-Multiple-Points","page":"Vectorized Operations","title":"CDF at Multiple Points","text":"using UniDist\n\nd = Exponential(5.0)\n\n# Compute survival curve\ntimes = [0, 1, 2, 5, 10, 20, 50]\nsurvival_probs = sf(d, times)\n\nprintln(\"Time\\tSurvival Probability\")\nfor (t, s) in zip(times, survival_probs)\n    println(\"$t\\t$(round(s * 100, digits=1))%\")\nend","category":"section"},{"location":"examples/vectorized/#Multiple-Quantiles","page":"Vectorized Operations","title":"Multiple Quantiles","text":"using UniDist\n\nd = Normal(100, 15)\n\n# Compute percentile table\npercentiles = 0.01:0.01:0.99\nvalues = quantile(d, collect(percentiles))\n\n# Find specific percentiles\np25 = quantile(d, 0.25)\np50 = quantile(d, 0.50)\np75 = quantile(d, 0.75)\n\nprintln(\"Q1: $p25, Median: $p50, Q3: $p75\")\nprintln(\"IQR: $(p75 - p25)\")\n\n","category":"section"},{"location":"examples/vectorized/#Combining-Vectorized-Parameters-and-Points","page":"Vectorized Operations","title":"Combining Vectorized Parameters and Points","text":"","category":"section"},{"location":"examples/vectorized/#Full-Grid-Evaluation","page":"Vectorized Operations","title":"Full Grid Evaluation","text":"using UniDist\n\n# Different exponential rates\nrates = [0.5, 1.0, 2.0]\ntimes = [0.5, 1.0, 2.0, 5.0]\n\nprintln(\"Survival probabilities S(t) = P(T > t)\")\nprintln(\"\\nTime\\tλ=0.5\\tλ=1.0\\tλ=2.0\")\n\nfor t in times\n    probs = [round(sf(Exponential(1/λ), t), digits=3) for λ in rates]\n    println(\"$t\\t$(probs[1])\\t$(probs[2])\\t$(probs[3])\")\nend\n\n","category":"section"},{"location":"examples/vectorized/#Practical-Applications","page":"Vectorized Operations","title":"Practical Applications","text":"","category":"section"},{"location":"examples/vectorized/#Sensitivity-Analysis","page":"Vectorized Operations","title":"Sensitivity Analysis","text":"using UniDist\n\n# How does changing parameters affect the 95th percentile?\nbase_mean = 100\nbase_sd = 15\n\n# Vary mean\nmeans = 90:5:110\nfor μ in means\n    d = Normal(μ, base_sd)\n    p95 = quantile(d, 0.95)\n    println(\"μ=$μ: 95th percentile = $(round(p95, digits=1))\")\nend\n\nprintln()\n\n# Vary standard deviation\nsds = 10:2:20\nfor σ in sds\n    d = Normal(base_mean, σ)\n    p95 = quantile(d, 0.95)\n    println(\"σ=$σ: 95th percentile = $(round(p95, digits=1))\")\nend","category":"section"},{"location":"examples/vectorized/#Comparing-Distribution-Families","page":"Vectorized Operations","title":"Comparing Distribution Families","text":"using UniDist\n\n# Compare different distributions with same mean and variance\n# Mean = 5, Variance = 5\n\ndistributions = [\n    (\"Gamma\", Gamma(5, 1)),           # shape=5, scale=1 → mean=5, var=5\n    (\"Normal\", Normal(5, sqrt(5))),   # mean=5, var=5\n]\n\nx_vals = 0:0.5:15\n\nprintln(\"x\\tGamma\\t\\tNormal\")\nfor x in x_vals\n    vals = [round(pdf(d, x), digits=4) for (_, d) in distributions]\n    println(\"$x\\t$(vals[1])\\t\\t$(vals[2])\")\nend","category":"section"},{"location":"examples/vectorized/#Batch-Risk-Calculations","page":"Vectorized Operations","title":"Batch Risk Calculations","text":"using UniDist\n\n# Calculate Value at Risk (VaR) for different confidence levels\n# Returns follow Normal(0.05, 0.20) - 5% expected return, 20% volatility\n\nreturns = Normal(0.05, 0.20)\nconfidence_levels = [0.90, 0.95, 0.99]\n\nprintln(\"VaR at different confidence levels:\")\nfor α in confidence_levels\n    var = -quantile(returns, 1 - α)\n    println(\"$(Int(α*100))% VaR: $(round(var * 100, digits=2))%\")\nend\n\n","category":"section"},{"location":"examples/vectorized/#Performance-Tips","page":"Vectorized Operations","title":"Performance Tips","text":"","category":"section"},{"location":"examples/vectorized/#Pre-allocating-Results","page":"Vectorized Operations","title":"Pre-allocating Results","text":"using UniDist\n\nd = Normal(0, 1)\nn = 10000\nxs = randn(n)\n\n# Efficient: single vectorized call\nresult = pdf(d, xs)","category":"section"},{"location":"examples/vectorized/#Avoiding-Repeated-Distribution-Creation","page":"Vectorized Operations","title":"Avoiding Repeated Distribution Creation","text":"using UniDist\n\n# Less efficient: creating distribution in loop\nfunction slow_version(means, x)\n    [pdf(Normal(μ, 1), x) for μ in means]\nend\n\n# More efficient: vectorized parameters\nfunction fast_version(means, x)\n    d = Normal(means, 1)\n    pdf(d, x)\nend\n\n","category":"section"},{"location":"examples/vectorized/#Working-with-Arrays","page":"Vectorized Operations","title":"Working with Arrays","text":"","category":"section"},{"location":"examples/vectorized/#Element-wise-Operations","page":"Vectorized Operations","title":"Element-wise Operations","text":"using UniDist\n\n# Array of different distribution types\ndistributions = [Normal(0, 1), Normal(0, 2), Normal(1, 1)]\n\n# Evaluate each at x = 0.5\nresults = [pdf(d, 0.5) for d in distributions]\n\n# Or using broadcasting syntax\nx = 0.5\nresults = pdf.(distributions, x)","category":"section"},{"location":"examples/vectorized/#Matrix-of-Probabilities","page":"Vectorized Operations","title":"Matrix of Probabilities","text":"using UniDist\n\n# Create probability matrix\n# Rows: different distributions\n# Columns: different x values\n\ndists = [Normal(0, 1), Normal(0, 2), Exponential(1)]\nxs = [0.0, 0.5, 1.0, 2.0]\n\nprob_matrix = [pdf(d, x) for d in dists, x in xs]\n\n# Display as table\nprintln(\"Distribution\\t\", join(xs, \"\\t\"))\nfor (i, d) in enumerate([\"N(0,1)\", \"N(0,2)\", \"Exp(1)\"])\n    row = [round(prob_matrix[i, j], digits=3) for j in 1:length(xs)]\n    println(\"$d\\t\\t\", join(row, \"\\t\"))\nend","category":"section"},{"location":"distributions/continuous/#continuous-distributions","page":"Continuous Distributions","title":"Continuous Distributions","text":"UniDist.jl provides 54 continuous probability distributions. This page documents each distribution with its parameters, support, and usage examples.","category":"section"},{"location":"distributions/continuous/#Common-Distributions","page":"Continuous Distributions","title":"Common Distributions","text":"","category":"section"},{"location":"distributions/continuous/#Normal-(Gaussian)","page":"Continuous Distributions","title":"Normal (Gaussian)","text":"The most widely used continuous distribution, characterized by its bell-shaped curve.\n\nNormal(μ, σ)  # μ = mean, σ = standard deviation\n\nParameters:\n\nμ (mu): Mean (location parameter)\nσ (sigma): Standard deviation (scale parameter), σ > 0\n\nSupport: (-∞, +∞)\n\nExample:\n\nd = Normal(0.0, 1.0)  # Standard normal\n\npdf(d, 0.0)           # ≈ 0.3989\ncdf(d, 1.96)          # ≈ 0.975\nquantile(d, 0.975)    # ≈ 1.96\nmean(d)               # 0.0\nvar(d)                # 1.0\n\nUse cases: Modeling measurement errors, natural phenomena, test scores, financial returns.\n\n","category":"section"},{"location":"distributions/continuous/#Exponential","page":"Continuous Distributions","title":"Exponential","text":"Models the time between events in a Poisson process.\n\nExponential(θ)  # θ = scale parameter (mean)\n\nParameters:\n\nθ (theta): Scale parameter (mean), θ > 0\n\nSupport: [0, +∞)\n\nExample:\n\nd = Exponential(2.0)  # Mean time = 2\n\npdf(d, 1.0)           # ≈ 0.303\ncdf(d, 2.0)           # ≈ 0.632\nmean(d)               # 2.0\n\nUse cases: Waiting times, survival analysis, reliability engineering, radioactive decay.\n\n","category":"section"},{"location":"distributions/continuous/#Uniform","page":"Continuous Distributions","title":"Uniform","text":"All values in an interval are equally likely.\n\nUniform(a, b)  # a = lower bound, b = upper bound\n\nParameters:\n\na: Lower bound\nb: Upper bound, b > a\n\nSupport: [a, b]\n\nExample:\n\nd = Uniform(0.0, 10.0)\n\npdf(d, 5.0)           # 0.1\ncdf(d, 5.0)           # 0.5\nquantile(d, 0.5)      # 5.0\nmean(d)               # 5.0\n\nUse cases: Random number generation, modeling complete uncertainty within bounds.\n\n","category":"section"},{"location":"distributions/continuous/#Beta","page":"Continuous Distributions","title":"Beta","text":"Flexible distribution on [0, 1], often used for probabilities.\n\nBeta(α, β)  # α, β = shape parameters\n\nParameters:\n\nα (alpha): Shape parameter, α > 0\nβ (beta): Shape parameter, β > 0\n\nSupport: [0, 1]\n\nExample:\n\nd = Beta(2.0, 5.0)\n\npdf(d, 0.3)           # ≈ 2.06\ncdf(d, 0.5)           # ≈ 0.89\nmean(d)               # ≈ 0.286\n\nUse cases: Bayesian inference for proportions, modeling probabilities, A/B testing.\n\n","category":"section"},{"location":"distributions/continuous/#Gamma","page":"Continuous Distributions","title":"Gamma","text":"Generalization of exponential distribution, models waiting times for multiple events.\n\nGamma(α, θ)  # α = shape, θ = scale\n\nParameters:\n\nα (alpha): Shape parameter, α > 0\nθ (theta): Scale parameter, θ > 0\n\nSupport: [0, +∞)\n\nExample:\n\nd = Gamma(2.0, 2.0)\n\npdf(d, 2.0)           # ≈ 0.184\ncdf(d, 4.0)           # ≈ 0.594\nmean(d)               # 4.0 (α * θ)\n\nUse cases: Waiting times, insurance claims, rainfall amounts, Bayesian inference.\n\n","category":"section"},{"location":"distributions/continuous/#Location-Scale-Distributions","page":"Continuous Distributions","title":"Location-Scale Distributions","text":"","category":"section"},{"location":"distributions/continuous/#Cauchy","page":"Continuous Distributions","title":"Cauchy","text":"Heavy-tailed distribution with no defined mean or variance.\n\nCauchy(x₀, γ)  # x₀ = location, γ = scale\n\nParameters:\n\nx₀: Location parameter\nγ (gamma): Scale parameter, γ > 0\n\nSupport: (-∞, +∞)\n\nExample:\n\nd = Cauchy(0.0, 1.0)  # Standard Cauchy\n\npdf(d, 0.0)           # ≈ 0.318\ncdf(d, 0.0)           # 0.5\n\nUse cases: Modeling outliers, ratio of normal variables, resonance in physics.\n\n","category":"section"},{"location":"distributions/continuous/#Laplace-(Double-Exponential)","page":"Continuous Distributions","title":"Laplace (Double Exponential)","text":"Symmetric distribution with heavier tails than normal.\n\nLaplace(μ, b)  # μ = location, b = scale\n\nParameters:\n\nμ (mu): Location parameter\nb: Scale parameter, b > 0\n\nSupport: (-∞, +∞)\n\nExample:\n\nd = Laplace(0.0, 1.0)\n\npdf(d, 0.0)           # 0.5\ncdf(d, 0.0)           # 0.5\n\nUse cases: Finance, signal processing, LASSO regression, robust estimation.\n\n","category":"section"},{"location":"distributions/continuous/#Logistic","page":"Continuous Distributions","title":"Logistic","text":"Similar to normal but with heavier tails.\n\nLogistic(μ, s)  # μ = location, s = scale\n\nParameters:\n\nμ (mu): Location (mean)\ns: Scale parameter, s > 0\n\nSupport: (-∞, +∞)\n\nExample:\n\nd = Logistic(0.0, 1.0)\n\npdf(d, 0.0)           # 0.25\ncdf(d, 0.0)           # 0.5\n\nUse cases: Logistic regression, growth models, neural networks.\n\n","category":"section"},{"location":"distributions/continuous/#Chi-Square-Family","page":"Continuous Distributions","title":"Chi-Square Family","text":"","category":"section"},{"location":"distributions/continuous/#ChiSquare","page":"Continuous Distributions","title":"ChiSquare","text":"Sum of squared standard normal variables.\n\nChiSquare(ν)  # ν = degrees of freedom\n\nParameters:\n\nν (nu): Degrees of freedom, ν > 0\n\nSupport: [0, +∞)\n\nExample:\n\nd = ChiSquare(5)\n\npdf(d, 3.0)           # ≈ 0.154\ncdf(d, 5.0)           # ≈ 0.584\nmean(d)               # 5.0\n\nUse cases: Hypothesis testing, confidence intervals, goodness-of-fit tests.\n\n","category":"section"},{"location":"distributions/continuous/#Chi","page":"Continuous Distributions","title":"Chi","text":"Square root of chi-square distribution.\n\nChi(ν)  # ν = degrees of freedom\n\nParameters:\n\nν (nu): Degrees of freedom, ν > 0\n\nSupport: [0, +∞)\n\n","category":"section"},{"location":"distributions/continuous/#F","page":"Continuous Distributions","title":"F","text":"Ratio of two chi-square distributions.\n\nF(ν₁, ν₂)  # ν₁, ν₂ = degrees of freedom\n\nParameters:\n\nν₁: Numerator degrees of freedom\nν₂: Denominator degrees of freedom\n\nSupport: [0, +∞)\n\nExample:\n\nd = F(5, 10)\n\npdf(d, 1.0)           # ≈ 0.61\ncdf(d, 2.0)           # ≈ 0.84\n\nUse cases: ANOVA, comparing variances, regression analysis.\n\n","category":"section"},{"location":"distributions/continuous/#Extreme-Value-Distributions","page":"Continuous Distributions","title":"Extreme Value Distributions","text":"","category":"section"},{"location":"distributions/continuous/#ExtremeValue-(Gumbel)","page":"Continuous Distributions","title":"ExtremeValue (Gumbel)","text":"Models the maximum of many samples.\n\nExtremeValue(μ, σ)  # μ = location, σ = scale\n\nParameters:\n\nμ (mu): Location parameter\nσ (sigma): Scale parameter, σ > 0\n\nSupport: (-∞, +∞)\n\nUse cases: Extreme weather events, flood analysis, material strength.\n\n","category":"section"},{"location":"distributions/continuous/#Weibull","page":"Continuous Distributions","title":"Weibull","text":"Flexible distribution for reliability and survival analysis.\n\nWeibull(α, θ)  # α = shape, θ = scale\n\nParameters:\n\nα (alpha): Shape parameter, α > 0\nθ (theta): Scale parameter, θ > 0\n\nSupport: [0, +∞)\n\nExample:\n\nd = Weibull(2.0, 1.0)\n\npdf(d, 0.5)           # ≈ 0.779\ncdf(d, 1.0)           # ≈ 0.632\n\nUse cases: Reliability engineering, failure analysis, wind speed modeling.\n\n","category":"section"},{"location":"distributions/continuous/#Pareto","page":"Continuous Distributions","title":"Pareto","text":"Heavy-tailed distribution following power law.\n\nPareto(α, θ)  # α = shape, θ = scale (minimum)\n\nParameters:\n\nα (alpha): Shape parameter, α > 0\nθ (theta): Scale (minimum value), θ > 0\n\nSupport: [θ, +∞)\n\nUse cases: Income distribution, city populations, file sizes, insurance claims.\n\n","category":"section"},{"location":"distributions/continuous/#Log-Transformed-Distributions","page":"Continuous Distributions","title":"Log-Transformed Distributions","text":"","category":"section"},{"location":"distributions/continuous/#LogNormal","page":"Continuous Distributions","title":"LogNormal","text":"Distribution of exp(X) where X is normal.\n\nLogNormal(μ, σ)  # μ, σ = parameters of log(X)\n\nParameters:\n\nμ (mu): Mean of log(X)\nσ (sigma): Standard deviation of log(X), σ > 0\n\nSupport: (0, +∞)\n\nExample:\n\nd = LogNormal(0.0, 1.0)\n\npdf(d, 1.0)           # ≈ 0.399\ncdf(d, 1.0)           # 0.5\n\nUse cases: Stock prices, income, biological measurements, particle sizes.\n\n","category":"section"},{"location":"distributions/continuous/#LogLogistic","page":"Continuous Distributions","title":"LogLogistic","text":"Log-transformed logistic distribution.\n\nLogLogistic(α, β)  # α = scale, β = shape\n\nSupport: (0, +∞)\n\nUse cases: Survival analysis, hydrology, economics.\n\n","category":"section"},{"location":"distributions/continuous/#Other-Continuous-Distributions","page":"Continuous Distributions","title":"Other Continuous Distributions","text":"","category":"section"},{"location":"distributions/continuous/#Arcsin","page":"Continuous Distributions","title":"Arcsin","text":"U-shaped distribution on [0, 1].\n\nArcsin(a, b)  # a = lower bound, b = upper bound\n\nSupport: [a, b]\n\n","category":"section"},{"location":"distributions/continuous/#Arctangent","page":"Continuous Distributions","title":"Arctangent","text":"Arctangent(θ, σ)\n\n","category":"section"},{"location":"distributions/continuous/#Erlang","page":"Continuous Distributions","title":"Erlang","text":"Special case of Gamma with integer shape.\n\nErlang(k, θ)  # k = shape (integer), θ = scale\n\nUse cases: Queuing theory, telecommunications.\n\n","category":"section"},{"location":"distributions/continuous/#Error","page":"Continuous Distributions","title":"Error","text":"Error(μ, σ, p)\n\n","category":"section"},{"location":"distributions/continuous/#ExponentialPower-(Generalized-Normal)","page":"Continuous Distributions","title":"ExponentialPower (Generalized Normal)","text":"ExponentialPower(μ, σ, p)\n\n","category":"section"},{"location":"distributions/continuous/#GeneralizedGamma","page":"Continuous Distributions","title":"GeneralizedGamma","text":"GeneralizedGamma(a, d, p)\n\n","category":"section"},{"location":"distributions/continuous/#GeneralizedPareto","page":"Continuous Distributions","title":"GeneralizedPareto","text":"GeneralizedPareto(μ, σ, ξ)\n\nUse cases: Extreme value analysis, tail risk modeling.\n\n","category":"section"},{"location":"distributions/continuous/#Gompertz","page":"Continuous Distributions","title":"Gompertz","text":"Gompertz(η, b)\n\nUse cases: Mortality modeling, actuarial science.\n\n","category":"section"},{"location":"distributions/continuous/#HyperbolicSecant","page":"Continuous Distributions","title":"HyperbolicSecant","text":"HyperbolicSecant(μ, σ)\n\n","category":"section"},{"location":"distributions/continuous/#Hyperexponential","page":"Continuous Distributions","title":"Hyperexponential","text":"Hyperexponential(probs, rates)\n\n","category":"section"},{"location":"distributions/continuous/#Hypoexponential","page":"Continuous Distributions","title":"Hypoexponential","text":"Hypoexponential(rates)\n\n","category":"section"},{"location":"distributions/continuous/#IDB-(Inverse-Beta-Distribution)","page":"Continuous Distributions","title":"IDB (Inverse Beta Distribution)","text":"IDB(α, β, θ)\n\n","category":"section"},{"location":"distributions/continuous/#InverseGaussian","page":"Continuous Distributions","title":"InverseGaussian","text":"InverseGaussian(μ, λ)\n\nUse cases: First passage times, reliability.\n\n","category":"section"},{"location":"distributions/continuous/#InvertedBeta","page":"Continuous Distributions","title":"InvertedBeta","text":"InvertedBeta(α, β)\n\n","category":"section"},{"location":"distributions/continuous/#InvertedGamma","page":"Continuous Distributions","title":"InvertedGamma","text":"InvertedGamma(α, θ)\n\nUse cases: Bayesian inference for variance.\n\n","category":"section"},{"location":"distributions/continuous/#KolmogorovSmirnov","page":"Continuous Distributions","title":"KolmogorovSmirnov","text":"KolmogorovSmirnov()\n\nUse cases: Goodness-of-fit testing.\n\n","category":"section"},{"location":"distributions/continuous/#LogGamma","page":"Continuous Distributions","title":"LogGamma","text":"LogGamma(α, β)\n\n","category":"section"},{"location":"distributions/continuous/#LogisticExponential","page":"Continuous Distributions","title":"LogisticExponential","text":"LogisticExponential(λ, κ)\n\n","category":"section"},{"location":"distributions/continuous/#Lomax-(Pareto-Type-II)","page":"Continuous Distributions","title":"Lomax (Pareto Type II)","text":"Lomax(α, λ)\n\n","category":"section"},{"location":"distributions/continuous/#Makeham","page":"Continuous Distributions","title":"Makeham","text":"Makeham(a, b, c)\n\nUse cases: Mortality modeling.\n\n","category":"section"},{"location":"distributions/continuous/#Minimax","page":"Continuous Distributions","title":"Minimax","text":"Minimax(β, γ)\n\n","category":"section"},{"location":"distributions/continuous/#Muth","page":"Continuous Distributions","title":"Muth","text":"Muth(α)\n\n","category":"section"},{"location":"distributions/continuous/#Power","page":"Continuous Distributions","title":"Power","text":"Power(α, a, b)\n\n","category":"section"},{"location":"distributions/continuous/#Rayleigh","page":"Continuous Distributions","title":"Rayleigh","text":"Rayleigh(σ)\n\nUse cases: Wind speed, wave height, signal processing.\n\n","category":"section"},{"location":"distributions/continuous/#Triangular","page":"Continuous Distributions","title":"Triangular","text":"Triangular(a, b, c)  # a = min, b = max, c = mode\n\nUse cases: Project management (PERT), when only min/max/mode are known.\n\n","category":"section"},{"location":"distributions/continuous/#VonMises","page":"Continuous Distributions","title":"VonMises","text":"Circular distribution for angular data.\n\nVonMises(μ, κ)  # μ = mean direction, κ = concentration\n\nUse cases: Wind directions, compass bearings, time-of-day data.\n\n","category":"section"},{"location":"distributions/continuous/#Noncentral-Distributions","page":"Continuous Distributions","title":"Noncentral Distributions","text":"","category":"section"},{"location":"distributions/continuous/#NoncentralBeta","page":"Continuous Distributions","title":"NoncentralBeta","text":"NoncentralBeta(α, β, λ)\n\n","category":"section"},{"location":"distributions/continuous/#NoncentralChiSquare","page":"Continuous Distributions","title":"NoncentralChiSquare","text":"NoncentralChiSquare(ν, λ)\n\nUse cases: Power analysis, signal detection.\n\n","category":"section"},{"location":"distributions/continuous/#NoncentralF","page":"Continuous Distributions","title":"NoncentralF","text":"NoncentralF(ν₁, ν₂, λ)\n\n","category":"section"},{"location":"distributions/continuous/#NoncentralT","page":"Continuous Distributions","title":"NoncentralT","text":"NoncentralT(ν, λ)\n\nUse cases: Power analysis, effect size calculations.\n\n","category":"section"},{"location":"distributions/continuous/#DoublyNoncentralF","page":"Continuous Distributions","title":"DoublyNoncentralF","text":"DoublyNoncentralF(ν₁, ν₂, λ₁, λ₂)\n\n","category":"section"},{"location":"distributions/continuous/#DoublyNoncentralT","page":"Continuous Distributions","title":"DoublyNoncentralT","text":"DoublyNoncentralT(ν, λ₁, λ₂)\n\n","category":"section"},{"location":"distributions/continuous/#Standard-(Parameterless)-Distributions","page":"Continuous Distributions","title":"Standard (Parameterless) Distributions","text":"These distributions have fixed parameters for convenience:\n\nStandardNormal()      # Normal(0, 1)\nStandardUniform()     # Uniform(0, 1)\nStandardCauchy()      # Cauchy(0, 1)\nStandardTriangular()  # Triangular(-1, 1, 0)\nStandardPower(α)      # Power distribution on [0, 1]\n\nExample:\n\nd = StandardNormal()\npdf(d, 0.0)           # ≈ 0.3989\ncdf(d, 1.96)          # ≈ 0.975","category":"section"},{"location":"#UniDist.jl","page":"Home","title":"UniDist.jl","text":"warning: Experimental\nThis package is experimental. The API may change without notice in future versions.\n\nUniDist.jl is a Julia package for working with univariate probability distributions. It provides a consistent, intuitive API for computing probability density functions, cumulative distribution functions, quantiles, random sampling, and more.","category":"section"},{"location":"#Key-Features","page":"Home","title":"Key Features","text":"70+ distributions: 19 discrete and 54 continuous distributions\nVectorized parameters: Pass arrays as distribution parameters for batch computations\nFamiliar API: Follows Julia's Distributions.jl conventions\nR-style shortcuts: Optional d, p, q, r functions for users familiar with R\nSurvival analysis: Built-in survival function, hazard, and cumulative hazard\nStatistical intervals: Equal-tailed intervals and highest density intervals (HDI)","category":"section"},{"location":"#Package-Overview","page":"Home","title":"Package Overview","text":"using UniDist\n\n# Create a distribution\nd = Normal(0.0, 1.0)\n\n# Compute probabilities\npdf(d, 0.0)       # 0.3989...\ncdf(d, 1.96)      # 0.975...\n\n# Generate samples\nsamples = r(d, 1000)\n\n# Statistical intervals\ninterval(d, 0.05)  # 95% confidence interval\nhdi(d, 0.95)       # 95% highest density interval","category":"section"},{"location":"#Documentation-Structure","page":"Home","title":"Documentation Structure","text":"Getting Started: Installation and first steps\nDistributions: Complete list of supported distributions\nContinuous Distributions\nDiscrete Distributions\nAPI Reference:\nCore Functions\nSurvival Analysis\nStatistical Intervals\nExamples: Real-world usage scenarios\nBasic Usage\nVectorized Operations\nStatistical Analysis\nBayesian Inference","category":"section"},{"location":"#Quick-Comparison-with-Other-Packages","page":"Home","title":"Quick Comparison with Other Packages","text":"Feature UniDist.jl Distributions.jl\nCore API (pdf, cdf, quantile) Yes Yes\nR-style shortcuts (d, p, q, r) Yes No\nSurvival functions Yes Partial\nHDI intervals Yes No\nVectorized parameters Yes Limited","category":"section"},{"location":"#References","page":"Home","title":"References","text":"This package is inspired by and based on the comprehensive survey of univariate distribution relationships:\n\nLeemis, L. M., & McQueston, J. T. (2008). Univariate Distribution Relationships. The American Statistician, 62(1), 45–53. https://doi.org/10.1198/000313008X270448\n\nThe paper provides a detailed chart showing the relationships between 76 univariate distributions, including transformations, special cases, and limiting relationships.","category":"section"},{"location":"#License","page":"Home","title":"License","text":"UniDist.jl is released under the MIT License. See LICENSE for details.","category":"section"}]
}
